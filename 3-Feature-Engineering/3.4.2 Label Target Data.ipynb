{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Label Target Data\n",
    "\n",
    "Up until this point, we have concerned ourselves mostly with understanding relationships between our feature space and the psuedo-target '% daily return'. In doing so, we were able to find relationships, many trigonomic, which could describe and fit the curve of a stocks returns. \n",
    "\n",
    "However, in live trading our goal is not to predict with one hundred percent accuracy the curve itself, but merely to label buy and sell points and communicate those to our broker to engage in transactions. This task is simpler in many ways. For example, it does not require us to be aware of the magnitude of impending moves, as long as we are in position to take advantage of them. Of course, if we were at the point we had to choose between two instruments, it would be nice to know which would move more significantly, but that is a problem for another period in time. \n",
    "\n",
    "For now, we will simply concern ourselves with labeling buy and sell points, or entries and exits, in our system. Therefore we must redefine both our target and feature space to aptly do so. \n",
    "\n",
    "Two simple solutions to the problem of labeling the target space present themselves. First, we could label the maximums and minimums and call it a day. This would leave us with a data sparsity problem: We would have very few buy and sell points, and many 'hold' points along the curve. In the past, we have taken such an approach and found ourselves forced to oversample data. This is a valid methodology, but the risk associated with it is that the machine will learn some very specific identifying feature of the oversampled data. Rather, we would prefer to ensure that it learns the general characteristics of the points we wish to identify. \n",
    "\n",
    "The second easy solution to this problem is to label all points buy or sell as long as you can make some minimum gain by doing so without incurring some heavy drawdown. This method does not suffer from the problem of sparse data, because now almost every point is either buy or sell. Previous attempts to implement this solution have also been met with failure. While the system was able to learn which points were which in training, during backtesting the system failed to produce a return. Further work could be done on this second solution, but for now we have been disappointed with the results. \n",
    "\n",
    "Given that we have concerned ourselves so far with implementation of trigonomic relationships in our data, a third solution might be a trigonomic one. We might theoretically concern ourselves with buying and selling in some range of radians measured by theta, and so sell only after the peak has turned down and the valley has turned up. We could theoretically calculate values in radians we wish to buy and sell at, and simply trade on that basis. \n",
    "\n",
    "The difficulty is, of course, correctly identifying where you are currently and making the corrrect decision thereof. Since we lack the ability to know for sure what the true angle of the function is currently, we must resort to labelling by hand all of the entry and exit points, and then building a model to relate those points to our estimated angles calculated earlier.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "\n",
    "1. Investigate optimal entry / exit points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Investigate optimal entry / exit points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our goal would be to buy and sell between the following ranges:\n",
    "\n",
    "#### Buy:\n",
    "\n",
    "$ .5\\pi < x < .75\\pi $\n",
    "\n",
    "#### Sell:\n",
    "\n",
    "$ 1.5\\pi < x < 1.75\\pi. $\n",
    "\n",
    "Theoretically, if the plot were a perfect sine wave, it would look like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,2*np.pi,100)\n",
    "y = np.sin(x - np.pi)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(x, y)\n",
    "plt.fill_betweenx(y=[-1,1.1], x1=[.5*np.pi, .5*np.pi], x2=[.75*np.pi,.75*np.pi], color='g', alpha=0.2, label='buy')\n",
    "plt.fill_betweenx(y=[-1,1.1], x1=[1.5*np.pi, 1.5*np.pi], x2=[1.75*np.pi,1.75*np.pi], color='r', alpha=0.2, label='sell')\n",
    "plt.title('Buy and Sell regions, sin(x - pi)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to buy and sell right after the trend turns, we hopefully give ourselves enough allowance to not exit early and reverse a position unfortunately. As it happens in real life, often a wave will appear to be coming to an end and then invert and continue upwards for a second cycle. We want to be careful not to be confused when that happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build a function that  to label the data\n",
    "\n",
    "In order to label the chart by hand, I will need a function that prints the chart, waits for input, stores the input, and then moves forward. \n",
    "\n",
    "It would be helpful to continue without having to label every point, so I should build in some functionality to infer the current point == the last point if input is null. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to create\n",
    "\n",
    "1. Load the y data for a stock\n",
    "2. Iterate over the y data and collect values \n",
    "3. Save\n",
    "4. Repeat for all 30 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sine_modules import load_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/screens/august25screen/'\n",
    "fn = 'key.csv'\n",
    "suffix = '.pickle'\n",
    "\n",
    "key_df = pd.read_csv('{}{}'.format(data_dir,fn))\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = key_df.sort_values(by='R2_score', ascending=False).head(30)['SYMBOL']\n",
    "\n",
    "sym = top_30.iloc[3]\n",
    "df = load_set(sym, data_dir, suffix)\n",
    "df = df[::-1].reset_index(drop=True)[::-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index[::-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[-180:+180:-1, 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from sys import exit\n",
    "\n",
    "def i_label(df):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    values = []\n",
    "    ind = []\n",
    "    \n",
    "    try:\n",
    "        for i in df.index[::-1]:\n",
    "            display.clear_output(wait=True)\n",
    "            plt.clf()\n",
    "            plt.axvline(i, c='r')\n",
    "            plt.plot(df.loc[i-25:i+25:-1, 'close'])\n",
    "            plt.xticks(np.arange(i-25,i+25))\n",
    "            display.display(plt.gcf())\n",
    "            x = input(\"Write something: \")\n",
    "            try:\n",
    "                values.append(int(x))\n",
    "                ind.append(i)\n",
    "#             except ValueError:\n",
    "#                 try:\n",
    "#                     values.append(values[-1])\n",
    "#                     ind.append(i)\n",
    "#                 except IndexError:\n",
    "#                     values.append(0)\n",
    "#                     ind.append(i)\n",
    "            except:\n",
    "                values.append(0)\n",
    "                ind.append(i)\n",
    "            if i == df.index[-1]:\n",
    "                display.clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        display.clear_output(wait=True)\n",
    "        return pd.Series(values, index=ind)\n",
    "    \n",
    "    return pd.Series(values, index=ind)\n",
    "\n",
    "seres = i_label(df)\n",
    "#print(seres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand labeling may be superior to algorithmic at the daily level. However, at the minute level this would entail hand labeling over 240,000 points. Even with the system above to do so, if I can do 100 points per minute for example, it would take 2400 minutes. This equates to 40 hours, or an entire working week of work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead I should write an algorithm to label these points the way I would want them labeled. In order to do so I must first understand my minimum return expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "plt.figure(figsize=(80,30))\n",
    "\n",
    "def get_ticks(close=df['close']):\n",
    "\n",
    "    mx = math.ceil(close.max())\n",
    "    mn = math.floor(close.min())\n",
    "\n",
    "    s = mn - .5\n",
    "    e = mx + .5\n",
    "    ticks = []\n",
    "    while s < e:\n",
    "        ticks.append(s)\n",
    "        s += .5\n",
    "\n",
    "    xticks = []\n",
    "    s = df.index[0] - 300\n",
    "    e = df.index[-1] + 300\n",
    "    while s < e:\n",
    "        xticks.append(s)\n",
    "        s += 100\n",
    "        \n",
    "    return ticks, xticks\n",
    "\n",
    "ticks, xticks = get_ticks()\n",
    "\n",
    "plt.plot(df['close'])\n",
    "plt.yticks(ticks)\n",
    "plt.xticks(xticks)\n",
    "plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn, mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say I wanted to design an algorithm, which given the data, would label buy and sell points every time a peak or valley turns, which could net at least \\\\$0.50. So, I would want to buy at the bottom and sell at the top, if the difference between the next wave is at least \\\\$0.50. Furthermore, I dont just want to label the high peak/lowest valley, nor do i want to label 100% of the points. I want roughly 25% of the points labeled with buy and sell, or 12.5% for each. This is still sparse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could bring in the smoother and write the algorithm on top of the output for that. Seems like a bit of unnessary abstraction though, does it not? \n",
    "\n",
    "Pros: \n",
    "- May give better results because the output of the smoothing function will be directly related to previous buy / sell points\n",
    "\n",
    "Cons: \n",
    "- A lot of work\n",
    "- Extra cycls in the work flow / change to the dataset\n",
    "- Why can't you just do it on the underlying data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_list = pd.Series(np.zeros(df.shape[0]), index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in df.index[::-1]:\n",
    "    for floc in df.index[-loc-1::-1]:\n",
    "        print((loc, floc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1, 'close'] / df.loc[0, 'close'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19.11 / 18.75 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_right(i, thres=0.01):\n",
    "    peak_flag = True\n",
    "    valley_flag = True\n",
    "    cp = df.loc[i, 'close'] \n",
    "    \n",
    "    while peak_flag == True or valley_flag == True:\n",
    "        try:\n",
    "            i += 1\n",
    "            np = df.loc[i, 'close'] \n",
    "            if np > cp:\n",
    "                peak_flag = False\n",
    "            if np < cp:\n",
    "                valley_flag = False\n",
    "            if np >= cp + thres and valley_flag == True:\n",
    "                return 1\n",
    "            if np <= cp - thres and peak_flag == True:\n",
    "                return -1\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    return False\n",
    "    \n",
    "def check_left(i, thres=0.01):\n",
    "    peak_flag = True\n",
    "    valley_flag = True\n",
    "    cp = df.loc[i, 'close'] \n",
    "    \n",
    "    while peak_flag == True or valley_flag == True:\n",
    "        try:\n",
    "            i -= 1\n",
    "            np = df.loc[i, 'close'] \n",
    "            if np > cp:\n",
    "                peak_flag = False\n",
    "            if np < cp:\n",
    "                valley_flag = False\n",
    "            if np >= cp + thres and valley_flag == True:\n",
    "                return 1\n",
    "            if np <= cp - thres and peak_flag == True:\n",
    "                return -1\n",
    "        except KeyError:\n",
    "            return False\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = np.zeros(np.shape(df.index)[0])\n",
    "thres= 0.25\n",
    "\n",
    "for j in df.index[::-1]:\n",
    "    r = check_right(j, thres)\n",
    "    l = check_left(j, thres)\n",
    "    if r == l:\n",
    "        locs[j] = r\n",
    "np.unique(locs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.where(locs == 1)\n",
    "s = np.where(locs == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "plt.plot(df['close'])\n",
    "plt.scatter(b[0]+1,df.loc[b]['close'], c='g')\n",
    "plt.scatter(s[0]+1,df.loc[s]['close'], c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def decision_label(df, thres_p = 0.002, crit_p=0.01):\n",
    "    thres = thres_p #.05\n",
    "    crit = crit_p #.4\n",
    "    length = df.shape[0]\n",
    "    decision_list = pd.Series(np.zeros(length), index = df.index)\n",
    "    #df['cmxs'] = minmax_scale(df['close'])\n",
    "    for loc in df.index[::-1]:\n",
    "        display.clear_output()\n",
    "        print('{:.2f}%'.format(loc/length*100))\n",
    "        max_diff = 0 \n",
    "        min_diff = 0\n",
    "        sell_flag = True\n",
    "        buy_flag = True \n",
    "\n",
    "        for floc in df.index[-loc-1::-1]:\n",
    "    #         time.sleep(1)\n",
    "    #         display.clear_output()\n",
    "    #         print(f'loc: {loc}')\n",
    "    #         print(f'Max diff: {max_diff}')\n",
    "    #         print(f'Min diff: {min_diff}')\n",
    "    #         print(f'Sell: {sell_flag}')\n",
    "    #         print(f'Buy: {buy_flag}')\n",
    "\n",
    "\n",
    "            val_diff = df.loc[floc, 'close'] / df.loc[loc, 'close'] - 1  \n",
    "            if val_diff > max_diff:\n",
    "                max_diff = val_diff\n",
    "            elif val_diff < min_diff:\n",
    "                min_diff = val_diff\n",
    "\n",
    "            if max_diff >= thres:\n",
    "                sell_flag = False\n",
    "            if min_diff <= -thres:\n",
    "                buy_flag = False\n",
    "\n",
    "            if sell_flag == True and min_diff <= -crit:\n",
    "                decision_list.loc[loc] = 2\n",
    "                break\n",
    "            if buy_flag == True and max_diff >= crit:\n",
    "                decision_list.loc[loc] = 1\n",
    "                break\n",
    "\n",
    "            if sell_flag == False and buy_flag == False:\n",
    "                break\n",
    "    return decision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = 0.005\n",
    "thres = crit\n",
    "df['decision'] = decision_label(df, crit, thres)\n",
    "\n",
    "#ticks, xticks = get_ticks(df['close'])\n",
    "plt.figure(figsize=(280,30))\n",
    "plt.plot(df['close'])\n",
    "plt.scatter(df[df['decision'] == 1].index, df[df['decision'] == 1].close, c='g')\n",
    "plt.scatter(df[df['decision'] == 2].index, df[df['decision'] == 2].close, c='r')\n",
    "#plt.yticks(ticks)\n",
    "#plt.xticks(xticks)\n",
    "plt.grid(b=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['decision'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff, min_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_p = 0.5 / (df['close'].max() - df['close'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_p = 0.05 / (df['close'].max() - df['close'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_p, thres_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Iteratively load all relevant data sets and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "save_dir = './data/prepared/august25screenfixed/'\n",
    "\n",
    "stocks = [f.split('.')[0] for f in listdir(save_dir) if isfile(join(save_dir, f))]\n",
    "len(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '.pickle'\n",
    "df = load_set(stocks[0], save_dir, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('_'.join(stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir, crit, thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 3, figsize=(150,200))\n",
    "fig.suptitle('Top 30 Consistent Performers w/ Decision Labels', fontsize=32)\n",
    "\n",
    "crit = 0.05\n",
    "thres = crit\n",
    "\n",
    "for i, stock in enumerate(stocks):\n",
    "    df = load_set(stock, save_dir, suffix)\n",
    "    \n",
    "    df['D2'] = decision_label(df, crit, thres)\n",
    "    \n",
    "    x,y = divmod(i, 3)\n",
    "    \n",
    "    ax[x, y].plot(df['close'])\n",
    "    ax[x, y].scatter(df[df['decision'] == 1].index, df[df['decision'] == 1].close, c='g')\n",
    "    ax[x, y].scatter(df[df['decision'] == 2].index, df[df['decision'] == 2].close, c='r')\n",
    "    ax[x, y].set_title(stock, fontsize=21)\n",
    "    ax[x, y].set_xlabel('Minutes since beginning of period')\n",
    "    ax[x, y].set_xlabel('Price ($)')\n",
    "    ax[x, y].yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax[x, y].xaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    plt.sca(ax[x,y])\n",
    "    plt.grid(b=True)\n",
    "    \n",
    "    df.to_pickle(f'{save_dir}{stock}{suffix}')\n",
    "#plt.savefig('./data/images/top30withDecisions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stock in enumerate(stocks):\n",
    "    df = load_set(stock, save_dir, suffix)\n",
    "    print(i, stock)\n",
    "    print(df['decision'].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t'.join(stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y matrix\n",
    "\n",
    "y = np.zeros([30,4000])\n",
    "\n",
    "for k, stock in enumerate(stocks):\n",
    "    df = load_set(stock, save_dir, suffix)\n",
    "    \n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "    e = df.shape[0]\n",
    "    l = e - 4000 - 2\n",
    "\n",
    "    y_ = df.iloc[l:e-2]['D2']\n",
    "    y[k] = y_.to_numpy() \n",
    "\n",
    "np.save('./data/prepared/august25screenfixed/numpy_matrices/yD2.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros([30,4000])\n",
    "\n",
    "for k, stock in enumerate(stocks):\n",
    "    df = load_set(stock, save_dir, suffix)\n",
    "    \n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "    e = df.shape[0]\n",
    "    l = e - 4000 - 59\n",
    "    \n",
    "    df['y'] = df['%close'].shift(1)\n",
    "    y_ = df.iloc[l:e-59]['y']\n",
    "    y[k] = y_.to_numpy() \n",
    "\n",
    "np.save('./data/prepared/august25screenfixed/numpy_matrices/y_br2.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= load_set(stocks[0], save_dir, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df['y_close'] = df['%close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([str(x) for x in df.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['%close','y_close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
