{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 LSTM on Return Close Target\n",
    "\n",
    "In this notebook we will attempt to learn on the decision labels 'D2', which have a 50/50 buy/sell split without hold positions indicated. We hope this will be an easier decision function to learn, rather than the 3 class classification of buy/hold/sell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('./data/prepared/august25screenfixed/numpy_matrices/y_br.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2000), (30, 2000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y[:, :2000]\n",
    "y_test = y[:, 2000:]\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1), (60000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape([60000, 1])\n",
    "y_test = y_test.reshape([60000, 1])\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/prepared/august25screenfixed/numpy_matrices/X_train.npy')\n",
    "X_test = np.load('./data/prepared/august25screenfixed/numpy_matrices/X_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 116, 60), (60000, 1, 116, 60))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.10514541, -0.06351351, -0.06047963, ...,  0.06489185,\n",
       "         0.06741573,  0.12470588]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.07625272, -0.061875  , -0.06145251, ...,  0.09659091,\n",
       "         0.09957627,  0.10841704]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b9dbf46cd0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Undersample to balance classes for training set ?\n",
    "b = np.where(y_train == 1)[0]\n",
    "s = np.where(y_train == 2)[0]\n",
    "\n",
    "bi = np.random.choice(b, size=21000, replace=False)\n",
    "si = np.random.choice(s, size=21000, replace=False)\n",
    "\n",
    "ind = np.concatenate([bi,si])\n",
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bac97bdd0da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ind' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(y_train[ind], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[ind]\n",
    "X_train = X_train[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 116, 60), (60000, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 116, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:,:,:,:10]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 116, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape = (60000, 116, 10)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease test size for runtime and memory concerns\n",
    "b = np.where(y_test == 1)[0]\n",
    "s = np.where(y_test == 2)[0]\n",
    "\n",
    "bi = np.random.choice(b, size=20000, replace=False)\n",
    "si = np.random.choice(s, size=20000, replace=False)\n",
    "\n",
    "indt = np.concatenate([bi,si])\n",
    "indt.shape\n",
    "\n",
    "y_test = y_test[indt]\n",
    "X_test = X_test[indt]\n",
    "y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 116, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[:,:,:,:10]\n",
    "X_test.shape = (60000, 116, 10)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)[1]/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True),np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[np.where(y_train == 2)] = 0\n",
    "y_test[np.where(y_test == 2)] = 0\n",
    "\n",
    "np.unique(y_train, return_counts=True),np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10, 116)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xr_tp = np.transpose(X_train, axes=(0,2,1))\n",
    "Xr_tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10, 116)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe_tp = np.transpose(X_test, axes=(0,2,1))\n",
    "Xe_tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 819.2574 - mean_squared_error: 819.2581 - val_loss: 770.8177 - val_mean_squared_error: 770.8179\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 819.1736 - mean_squared_error: 819.1735 - val_loss: 770.9350 - val_mean_squared_error: 770.9357\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 819.1198 - mean_squared_error: 819.1199 - val_loss: 770.9629 - val_mean_squared_error: 770.9623\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 16s 261us/sample - loss: 819.0930 - mean_squared_error: 819.0927 - val_loss: 770.8600 - val_mean_squared_error: 770.8605\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 15s 257us/sample - loss: 819.0596 - mean_squared_error: 819.0594 - val_loss: 770.8098 - val_mean_squared_error: 770.8100\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 16s 266us/sample - loss: 819.0399 - mean_squared_error: 819.0397 - val_loss: 770.8420 - val_mean_squared_error: 770.8419\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 819.0080 - mean_squared_error: 819.0089 - val_loss: 770.9187 - val_mean_squared_error: 770.9192\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 15s 254us/sample - loss: 819.0168 - mean_squared_error: 819.0162 - val_loss: 770.8732 - val_mean_squared_error: 770.8728\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 818.9957 - mean_squared_error: 818.9951 - val_loss: 770.9784 - val_mean_squared_error: 770.9772\n",
      "Epoch 10/50\n",
      "13600/60000 [=====>........................] - ETA: 8s - loss: 831.4316 - mean_squared_error: 831.4318"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8bd19a0bca02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.fit(Xr_tp, yr_b, epochs=50,\n\u001b[0;32m---> 12\u001b[0;31m          validation_data=(Xe_tp, ye_b))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# V2 control flow relies on XLAControlFlowContext to generate a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_tracing_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(1),\n",
    "    keras.layers.Dense(1)\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "model.fit(Xr_tp, yr_b, epochs=5,\n",
    "         validation_data=(Xe_tp, ye_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_b = y_train*10**4\n",
    "ye_b = y_test*10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([32831, 27169]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yr_d = y_train.copy()\n",
    "yr_d[np.where(yr_d > 0)] = 1\n",
    "yr_d[np.where(yr_d < 0)] = 0\n",
    "np.unique(yr_d, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([33401, 26599]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ye_d = y_test.copy()\n",
    "ye_d[np.where(ye_d > 0)] = 1\n",
    "ye_d[np.where(ye_d < 0)] = 0\n",
    "np.unique(ye_d, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.6870 - accuracy: 0.5447 - val_loss: 0.6835 - val_accuracy: 0.5563\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.6848 - accuracy: 0.5456 - val_loss: 0.6820 - val_accuracy: 0.5563\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.6837 - accuracy: 0.5469 - val_loss: 0.6832 - val_accuracy: 0.5567\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.6832 - accuracy: 0.5474 - val_loss: 0.6818 - val_accuracy: 0.5579\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.6821 - accuracy: 0.5518 - val_loss: 0.6800 - val_accuracy: 0.5624\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 0.6803 - accuracy: 0.5596 - val_loss: 0.6793 - val_accuracy: 0.5610\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.6778 - accuracy: 0.5688 - val_loss: 0.6777 - val_accuracy: 0.5627\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.6727 - accuracy: 0.5793 - val_loss: 0.6687 - val_accuracy: 0.5854\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.6607 - accuracy: 0.6040 - val_loss: 0.6499 - val_accuracy: 0.6158\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.6456 - accuracy: 0.6263 - val_loss: 0.6329 - val_accuracy: 0.6518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f794426abd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(10),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55668333, 0.44331667])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ye_d, return_counts=True)[1]/np.shape(ye_d)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.6344 - accuracy: 0.6447 - val_loss: 0.6259 - val_accuracy: 0.6592\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 15s 242us/sample - loss: 0.6275 - accuracy: 0.6534 - val_loss: 0.6204 - val_accuracy: 0.6666\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 0.6170 - accuracy: 0.6677 - val_loss: 0.6098 - val_accuracy: 0.6791\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 0.6099 - accuracy: 0.6761 - val_loss: 0.5981 - val_accuracy: 0.6935\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.6001 - accuracy: 0.6892 - val_loss: 0.6066 - val_accuracy: 0.6822\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.5870 - accuracy: 0.7067 - val_loss: 0.5770 - val_accuracy: 0.7182\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.5724 - accuracy: 0.7216 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.5523 - accuracy: 0.7457 - val_loss: 0.5427 - val_accuracy: 0.7594\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 245us/sample - loss: 0.5328 - accuracy: 0.7682 - val_loss: 0.5169 - val_accuracy: 0.7855\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.5214 - accuracy: 0.7809 - val_loss: 0.5228 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f793c099ad0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.5053 - accuracy: 0.7983 - val_loss: 0.5113 - val_accuracy: 0.7887\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 214us/sample - loss: 0.4981 - accuracy: 0.8036 - val_loss: 0.4825 - val_accuracy: 0.8217\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.4916 - accuracy: 0.8118 - val_loss: 0.4775 - val_accuracy: 0.8285\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.4834 - accuracy: 0.8206 - val_loss: 0.4702 - val_accuracy: 0.8370\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.4712 - accuracy: 0.8352 - val_loss: 0.4602 - val_accuracy: 0.8461\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 0.4676 - accuracy: 0.8386 - val_loss: 0.4644 - val_accuracy: 0.8397\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 0.4644 - accuracy: 0.8403 - val_loss: 0.4480 - val_accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.4529 - accuracy: 0.8536 - val_loss: 0.4552 - val_accuracy: 0.8527\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.4499 - accuracy: 0.8565 - val_loss: 0.4431 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.4493 - accuracy: 0.8570 - val_loss: 0.4327 - val_accuracy: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f793c062d10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.4409 - accuracy: 0.8674 - val_loss: 0.4413 - val_accuracy: 0.8666\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.4392 - accuracy: 0.8680 - val_loss: 0.4249 - val_accuracy: 0.8844\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.4344 - accuracy: 0.8737 - val_loss: 0.4285 - val_accuracy: 0.8801\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 214us/sample - loss: 0.4320 - accuracy: 0.8762 - val_loss: 0.4851 - val_accuracy: 0.8162\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.4282 - accuracy: 0.8798 - val_loss: 0.4299 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 0.4246 - accuracy: 0.8834 - val_loss: 0.4154 - val_accuracy: 0.8938\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 0.4236 - accuracy: 0.8846 - val_loss: 0.4339 - val_accuracy: 0.8711\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 15s 247us/sample - loss: 0.4225 - accuracy: 0.8862 - val_loss: 0.4351 - val_accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.4183 - accuracy: 0.8903 - val_loss: 0.4070 - val_accuracy: 0.9033\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.4153 - accuracy: 0.8931 - val_loss: 0.4104 - val_accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f793c07bf10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 251us/sample - loss: 0.4150 - accuracy: 0.8941 - val_loss: 0.4071 - val_accuracy: 0.9020\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 15s 245us/sample - loss: 0.4144 - accuracy: 0.8941 - val_loss: 0.4070 - val_accuracy: 0.9027\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.4111 - accuracy: 0.8984 - val_loss: 0.4009 - val_accuracy: 0.9100\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.4108 - accuracy: 0.8987 - val_loss: 0.4091 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.4099 - accuracy: 0.8988 - val_loss: 0.4678 - val_accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.4063 - accuracy: 0.9028 - val_loss: 0.4078 - val_accuracy: 0.9007\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.4077 - accuracy: 0.9012 - val_loss: 0.4178 - val_accuracy: 0.8894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.4076 - accuracy: 0.9012 - val_loss: 0.3963 - val_accuracy: 0.9137\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.4022 - accuracy: 0.9068 - val_loss: 0.4016 - val_accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 0.4030 - accuracy: 0.9053 - val_loss: 0.3978 - val_accuracy: 0.9125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f793c0f5a50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./data/Models/1min91acc_010920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/Models/1min91acc_010920/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./data/Models/1min91acc_010920') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.3786 - accuracy: 0.9351 - val_loss: 0.3805 - val_accuracy: 0.9329\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.3762 - accuracy: 0.9374 - val_loss: 0.3803 - val_accuracy: 0.9327\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.3753 - accuracy: 0.9383 - val_loss: 0.3810 - val_accuracy: 0.9324\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.3747 - accuracy: 0.9387 - val_loss: 0.3798 - val_accuracy: 0.9319\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.3742 - accuracy: 0.9392 - val_loss: 0.3793 - val_accuracy: 0.9332\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 0.3735 - accuracy: 0.9403 - val_loss: 0.3790 - val_accuracy: 0.9332\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.3726 - accuracy: 0.9411 - val_loss: 0.3795 - val_accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.3722 - accuracy: 0.9420 - val_loss: 0.3778 - val_accuracy: 0.9347\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 0.3720 - accuracy: 0.9420 - val_loss: 0.3790 - val_accuracy: 0.9330\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.3715 - accuracy: 0.9419 - val_loss: 0.3788 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7944217350>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.3689 - accuracy: 0.9456 - val_loss: 0.3763 - val_accuracy: 0.9364\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.3684 - accuracy: 0.9465 - val_loss: 0.3764 - val_accuracy: 0.9363\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.3682 - accuracy: 0.9467 - val_loss: 0.3769 - val_accuracy: 0.9354\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.3682 - accuracy: 0.9466 - val_loss: 0.3761 - val_accuracy: 0.9366\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 0.3681 - accuracy: 0.9474 - val_loss: 0.3760 - val_accuracy: 0.9366\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 241us/sample - loss: 0.3680 - accuracy: 0.9471 - val_loss: 0.3759 - val_accuracy: 0.9366\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.3680 - accuracy: 0.9469 - val_loss: 0.3759 - val_accuracy: 0.9370\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.3679 - accuracy: 0.9476 - val_loss: 0.3762 - val_accuracy: 0.9367\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.3679 - accuracy: 0.9471 - val_loss: 0.3761 - val_accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.3678 - accuracy: 0.9474 - val_loss: 0.3758 - val_accuracy: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7934140250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
