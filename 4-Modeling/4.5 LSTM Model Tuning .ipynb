{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 LSTM Model Tuning \n",
    "\n",
    "In the previous notebook we saw excellent performance on our LSTM(10) model. In this notebook we will try different configurations (LSTM(12) and LSTM(8)) to see whether we can further enhance the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('./data/prepared/august25screenfixed/numpy_matrices/y_br.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2000), (30, 2000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y[:, :2000]\n",
    "y_test = y[:, 2000:]\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1), (60000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape([60000, 1])\n",
    "y_test = y_test.reshape([60000, 1])\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/prepared/august25screenfixed/numpy_matrices/X_train.npy')\n",
    "X_test = np.load('./data/prepared/august25screenfixed/numpy_matrices/X_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 116, 60), (60000, 1, 116, 60))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 116, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:,:,:,:10]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 116, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape = (60000, 116, 10)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 116, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[:,:,:,:10]\n",
    "X_test.shape = (60000, 116, 10)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10, 116)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xr_tp = np.transpose(X_train, axes=(0,2,1))\n",
    "Xr_tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10, 116)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe_tp = np.transpose(X_test, axes=(0,2,1))\n",
    "Xe_tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([32831, 27169]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yr_d = y_train.copy()\n",
    "yr_d[np.where(yr_d > 0)] = 1\n",
    "yr_d[np.where(yr_d < 0)] = 0\n",
    "np.unique(yr_d, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([33401, 26599]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ye_d = y_test.copy()\n",
    "ye_d[np.where(ye_d > 0)] = 1\n",
    "ye_d[np.where(ye_d < 0)] = 0\n",
    "np.unique(ye_d, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 21s 343us/sample - loss: 0.6878 - accuracy: 0.5465 - val_loss: 0.6851 - val_accuracy: 0.5567\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.6848 - accuracy: 0.5452 - val_loss: 0.6821 - val_accuracy: 0.5567\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 25s 408us/sample - loss: 0.6846 - accuracy: 0.5463 - val_loss: 0.6881 - val_accuracy: 0.5350\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.6839 - accuracy: 0.5465 - val_loss: 0.6822 - val_accuracy: 0.5504\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 20s 327us/sample - loss: 0.6832 - accuracy: 0.5490 - val_loss: 0.6810 - val_accuracy: 0.5572\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 20s 330us/sample - loss: 0.6823 - accuracy: 0.5514 - val_loss: 0.6809 - val_accuracy: 0.5586\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 22s 364us/sample - loss: 0.6806 - accuracy: 0.5580 - val_loss: 0.6782 - val_accuracy: 0.5645\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.6787 - accuracy: 0.5645 - val_loss: 0.6752 - val_accuracy: 0.5789\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 20s 330us/sample - loss: 0.6745 - accuracy: 0.5770 - val_loss: 0.6727 - val_accuracy: 0.5763\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 19s 324us/sample - loss: 0.6654 - accuracy: 0.5953 - val_loss: 0.6580 - val_accuracy: 0.6086\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 20s 335us/sample - loss: 0.6531 - accuracy: 0.6169 - val_loss: 0.6438 - val_accuracy: 0.6334\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 20s 332us/sample - loss: 0.6439 - accuracy: 0.6304 - val_loss: 0.6395 - val_accuracy: 0.6386\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 20s 339us/sample - loss: 0.6330 - accuracy: 0.6480 - val_loss: 0.6237 - val_accuracy: 0.6602\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.6260 - accuracy: 0.6562 - val_loss: 0.6250 - val_accuracy: 0.6571\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 22s 365us/sample - loss: 0.6190 - accuracy: 0.6651 - val_loss: 0.6076 - val_accuracy: 0.6798\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 20s 340us/sample - loss: 0.6124 - accuracy: 0.6729 - val_loss: 0.6156 - val_accuracy: 0.6714\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 21s 346us/sample - loss: 0.6036 - accuracy: 0.6859 - val_loss: 0.5999 - val_accuracy: 0.6913\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 21s 356us/sample - loss: 0.5948 - accuracy: 0.6961 - val_loss: 0.5867 - val_accuracy: 0.7047\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.5877 - accuracy: 0.7045 - val_loss: 0.5906 - val_accuracy: 0.7029\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 22s 367us/sample - loss: 0.5768 - accuracy: 0.7169 - val_loss: 0.5697 - val_accuracy: 0.7290\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.5704 - accuracy: 0.7241 - val_loss: 0.5642 - val_accuracy: 0.7319\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 20s 339us/sample - loss: 0.5618 - accuracy: 0.7337 - val_loss: 0.5542 - val_accuracy: 0.7427\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 20s 341us/sample - loss: 0.5568 - accuracy: 0.7402 - val_loss: 0.5639 - val_accuracy: 0.7329\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 20s 340us/sample - loss: 0.5504 - accuracy: 0.7469 - val_loss: 0.5426 - val_accuracy: 0.7567\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.5446 - accuracy: 0.7534 - val_loss: 0.5323 - val_accuracy: 0.7682\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 20s 332us/sample - loss: 0.5359 - accuracy: 0.7634 - val_loss: 0.5249 - val_accuracy: 0.7742\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 20s 332us/sample - loss: 0.5304 - accuracy: 0.7698 - val_loss: 0.5174 - val_accuracy: 0.7850\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 19s 319us/sample - loss: 0.5232 - accuracy: 0.7766 - val_loss: 0.5118 - val_accuracy: 0.7890\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 21s 345us/sample - loss: 0.5163 - accuracy: 0.7850 - val_loss: 0.5265 - val_accuracy: 0.7727\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.5070 - accuracy: 0.7948 - val_loss: 0.4990 - val_accuracy: 0.8045\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 21s 342us/sample - loss: 0.5027 - accuracy: 0.7987 - val_loss: 0.4924 - val_accuracy: 0.8110\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.4989 - accuracy: 0.8028 - val_loss: 0.4885 - val_accuracy: 0.8142\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.4960 - accuracy: 0.8081 - val_loss: 0.5099 - val_accuracy: 0.7931\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 20s 335us/sample - loss: 0.4919 - accuracy: 0.8112 - val_loss: 0.4853 - val_accuracy: 0.8179\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 21s 358us/sample - loss: 0.4867 - accuracy: 0.8165 - val_loss: 0.5088 - val_accuracy: 0.7911\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 23s 375us/sample - loss: 0.4824 - accuracy: 0.8226 - val_loss: 0.4792 - val_accuracy: 0.8253\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 19s 320us/sample - loss: 0.4820 - accuracy: 0.8216 - val_loss: 0.4878 - val_accuracy: 0.8135\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 22s 363us/sample - loss: 0.4770 - accuracy: 0.8276 - val_loss: 0.4823 - val_accuracy: 0.8213\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.4732 - accuracy: 0.8310 - val_loss: 0.4667 - val_accuracy: 0.8381\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.4709 - accuracy: 0.8342 - val_loss: 0.4650 - val_accuracy: 0.8399\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 23s 382us/sample - loss: 0.4688 - accuracy: 0.8361 - val_loss: 0.4740 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.4662 - accuracy: 0.8374 - val_loss: 0.4959 - val_accuracy: 0.8043\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.4635 - accuracy: 0.8416 - val_loss: 0.4565 - val_accuracy: 0.8498\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 21s 358us/sample - loss: 0.4646 - accuracy: 0.8408 - val_loss: 0.4645 - val_accuracy: 0.8401\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.4611 - accuracy: 0.8445 - val_loss: 0.4750 - val_accuracy: 0.8284\n",
      "Epoch 46/100\n",
      "22560/60000 [==========>...................] - ETA: 9s - loss: 0.4605 - accuracy: 0.8440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-58701acbb8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.fit(Xr_tp, yr_d, epochs=100,\n\u001b[0;32m---> 12\u001b[0;31m          validation_data=(Xe_tp, ye_d))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(12),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=100,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('./data/Models/1min91acc_010920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/Models/1min91acc_010920/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('./data/Models/1min91acc_010920') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 366us/sample - loss: 0.4350 - accuracy: 0.8739 - val_loss: 0.4421 - val_accuracy: 0.8658\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.4328 - accuracy: 0.8760 - val_loss: 0.4400 - val_accuracy: 0.8679\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.4321 - accuracy: 0.8768 - val_loss: 0.4405 - val_accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.4310 - accuracy: 0.8779 - val_loss: 0.4398 - val_accuracy: 0.8677\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.4304 - accuracy: 0.8783 - val_loss: 0.4433 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 17s 276us/sample - loss: 0.4302 - accuracy: 0.8778 - val_loss: 0.4374 - val_accuracy: 0.8704\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.4297 - accuracy: 0.8791 - val_loss: 0.4376 - val_accuracy: 0.8694\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.4285 - accuracy: 0.8795 - val_loss: 0.4376 - val_accuracy: 0.8702\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.4286 - accuracy: 0.8800 - val_loss: 0.4386 - val_accuracy: 0.8679\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 16s 274us/sample - loss: 0.4278 - accuracy: 0.8810 - val_loss: 0.4370 - val_accuracy: 0.8704\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 18s 292us/sample - loss: 0.4271 - accuracy: 0.8817 - val_loss: 0.4364 - val_accuracy: 0.8709\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.4270 - accuracy: 0.8816 - val_loss: 0.4359 - val_accuracy: 0.8709\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.4263 - accuracy: 0.8826 - val_loss: 0.4364 - val_accuracy: 0.8705\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.4262 - accuracy: 0.8827 - val_loss: 0.4346 - val_accuracy: 0.8727\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.4260 - accuracy: 0.8832 - val_loss: 0.4351 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 16s 274us/sample - loss: 0.4252 - accuracy: 0.8845 - val_loss: 0.4340 - val_accuracy: 0.8730\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 21s 353us/sample - loss: 0.4253 - accuracy: 0.8834 - val_loss: 0.4349 - val_accuracy: 0.8727\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.4243 - accuracy: 0.8845 - val_loss: 0.4349 - val_accuracy: 0.8726\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 23s 378us/sample - loss: 0.4246 - accuracy: 0.8839 - val_loss: 0.4334 - val_accuracy: 0.8743\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 22s 360us/sample - loss: 0.4239 - accuracy: 0.8859 - val_loss: 0.4326 - val_accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9948399810>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=20,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 28s 459us/sample - loss: 0.4207 - accuracy: 0.8898 - val_loss: 0.4322 - val_accuracy: 0.8756\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 22s 362us/sample - loss: 0.4202 - accuracy: 0.8903 - val_loss: 0.4321 - val_accuracy: 0.8751\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 318us/sample - loss: 0.4201 - accuracy: 0.8902 - val_loss: 0.4327 - val_accuracy: 0.8747\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 31s 522us/sample - loss: 0.4201 - accuracy: 0.8903 - val_loss: 0.4320 - val_accuracy: 0.8757\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s 329us/sample - loss: 0.4200 - accuracy: 0.8901 - val_loss: 0.4319 - val_accuracy: 0.8755\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 347us/sample - loss: 0.4200 - accuracy: 0.8903 - val_loss: 0.4318 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 20s 325us/sample - loss: 0.4199 - accuracy: 0.8900 - val_loss: 0.4317 - val_accuracy: 0.8762\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 21s 343us/sample - loss: 0.4198 - accuracy: 0.8902 - val_loss: 0.4319 - val_accuracy: 0.8754\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 20s 338us/sample - loss: 0.4198 - accuracy: 0.8907 - val_loss: 0.4319 - val_accuracy: 0.8756\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 365us/sample - loss: 0.4198 - accuracy: 0.8906 - val_loss: 0.4321 - val_accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f994831f450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, LSTM(12) underperformed LSTM(10). Let's try LSTM(8). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/65\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.6878 - accuracy: 0.5452 - val_loss: 0.6885 - val_accuracy: 0.5277\n",
      "Epoch 2/65\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.6854 - accuracy: 0.5456 - val_loss: 0.6827 - val_accuracy: 0.5544\n",
      "Epoch 3/65\n",
      "60000/60000 [==============================] - 19s 320us/sample - loss: 0.6842 - accuracy: 0.5460 - val_loss: 0.6824 - val_accuracy: 0.5567\n",
      "Epoch 4/65\n",
      "60000/60000 [==============================] - 21s 354us/sample - loss: 0.6833 - accuracy: 0.5455 - val_loss: 0.6812 - val_accuracy: 0.5571\n",
      "Epoch 5/65\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.6826 - accuracy: 0.5505 - val_loss: 0.6804 - val_accuracy: 0.5602\n",
      "Epoch 6/65\n",
      "60000/60000 [==============================] - 21s 357us/sample - loss: 0.6817 - accuracy: 0.5533 - val_loss: 0.6824 - val_accuracy: 0.5519\n",
      "Epoch 7/65\n",
      "60000/60000 [==============================] - 25s 419us/sample - loss: 0.6804 - accuracy: 0.5587 - val_loss: 0.6802 - val_accuracy: 0.5593\n",
      "Epoch 8/65\n",
      "60000/60000 [==============================] - 25s 412us/sample - loss: 0.6786 - accuracy: 0.5633 - val_loss: 0.6812 - val_accuracy: 0.5557\n",
      "Epoch 9/65\n",
      "60000/60000 [==============================] - 22s 365us/sample - loss: 0.6756 - accuracy: 0.5730 - val_loss: 0.6733 - val_accuracy: 0.5831\n",
      "Epoch 10/65\n",
      "60000/60000 [==============================] - 21s 356us/sample - loss: 0.6704 - accuracy: 0.5858 - val_loss: 0.6694 - val_accuracy: 0.5866\n",
      "Epoch 11/65\n",
      "60000/60000 [==============================] - 21s 354us/sample - loss: 0.6635 - accuracy: 0.5990 - val_loss: 0.6667 - val_accuracy: 0.5942\n",
      "Epoch 12/65\n",
      "60000/60000 [==============================] - 20s 335us/sample - loss: 0.6577 - accuracy: 0.6102 - val_loss: 0.6618 - val_accuracy: 0.6004\n",
      "Epoch 13/65\n",
      "60000/60000 [==============================] - 20s 338us/sample - loss: 0.6499 - accuracy: 0.6210 - val_loss: 0.6411 - val_accuracy: 0.6409\n",
      "Epoch 14/65\n",
      "60000/60000 [==============================] - 21s 342us/sample - loss: 0.6406 - accuracy: 0.6363 - val_loss: 0.6362 - val_accuracy: 0.6402\n",
      "Epoch 15/65\n",
      "60000/60000 [==============================] - 21s 357us/sample - loss: 0.6296 - accuracy: 0.6513 - val_loss: 0.6145 - val_accuracy: 0.6748\n",
      "Epoch 16/65\n",
      "60000/60000 [==============================] - 21s 351us/sample - loss: 0.6205 - accuracy: 0.6633 - val_loss: 0.6230 - val_accuracy: 0.6561\n",
      "Epoch 17/65\n",
      "60000/60000 [==============================] - 22s 371us/sample - loss: 0.6107 - accuracy: 0.6773 - val_loss: 0.6044 - val_accuracy: 0.6812\n",
      "Epoch 18/65\n",
      "60000/60000 [==============================] - 25s 419us/sample - loss: 0.6032 - accuracy: 0.6850 - val_loss: 0.5896 - val_accuracy: 0.7009\n",
      "Epoch 19/65\n",
      "60000/60000 [==============================] - 27s 447us/sample - loss: 0.5911 - accuracy: 0.7009 - val_loss: 0.5833 - val_accuracy: 0.7074\n",
      "Epoch 20/65\n",
      "60000/60000 [==============================] - 42s 693us/sample - loss: 0.5815 - accuracy: 0.7112 - val_loss: 0.5796 - val_accuracy: 0.7144\n",
      "Epoch 21/65\n",
      "60000/60000 [==============================] - 28s 459us/sample - loss: 0.5726 - accuracy: 0.7219 - val_loss: 0.5640 - val_accuracy: 0.7312\n",
      "Epoch 22/65\n",
      "60000/60000 [==============================] - 32s 531us/sample - loss: 0.5642 - accuracy: 0.7328 - val_loss: 0.5917 - val_accuracy: 0.6933\n",
      "Epoch 23/65\n",
      "60000/60000 [==============================] - 15s 247us/sample - loss: 0.5552 - accuracy: 0.7419 - val_loss: 0.5660 - val_accuracy: 0.7257\n",
      "Epoch 24/65\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.5430 - accuracy: 0.7553 - val_loss: 0.5270 - val_accuracy: 0.7729\n",
      "Epoch 25/65\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.5332 - accuracy: 0.7676 - val_loss: 0.5188 - val_accuracy: 0.7831\n",
      "Epoch 26/65\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.5277 - accuracy: 0.7732 - val_loss: 0.5235 - val_accuracy: 0.7779\n",
      "Epoch 27/65\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.5180 - accuracy: 0.7842 - val_loss: 0.5275 - val_accuracy: 0.7721\n",
      "Epoch 28/65\n",
      "60000/60000 [==============================] - 21s 350us/sample - loss: 0.5130 - accuracy: 0.7891 - val_loss: 0.5111 - val_accuracy: 0.7885\n",
      "Epoch 29/65\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.5051 - accuracy: 0.7972 - val_loss: 0.4901 - val_accuracy: 0.8179\n",
      "Epoch 30/65\n",
      "60000/60000 [==============================] - 20s 338us/sample - loss: 0.4987 - accuracy: 0.8044 - val_loss: 0.4807 - val_accuracy: 0.8238\n",
      "Epoch 31/65\n",
      "60000/60000 [==============================] - 19s 324us/sample - loss: 0.4895 - accuracy: 0.8156 - val_loss: 0.4954 - val_accuracy: 0.8088\n",
      "Epoch 32/65\n",
      "60000/60000 [==============================] - 23s 382us/sample - loss: 0.4871 - accuracy: 0.8178 - val_loss: 0.4736 - val_accuracy: 0.8322\n",
      "Epoch 33/65\n",
      "60000/60000 [==============================] - 21s 347us/sample - loss: 0.4814 - accuracy: 0.8227 - val_loss: 0.4722 - val_accuracy: 0.8334\n",
      "Epoch 34/65\n",
      "60000/60000 [==============================] - 22s 365us/sample - loss: 0.4765 - accuracy: 0.8285 - val_loss: 0.4906 - val_accuracy: 0.8131\n",
      "Epoch 35/65\n",
      "60000/60000 [==============================] - 22s 362us/sample - loss: 0.4730 - accuracy: 0.8331 - val_loss: 0.4603 - val_accuracy: 0.8491\n",
      "Epoch 36/65\n",
      "60000/60000 [==============================] - 22s 371us/sample - loss: 0.4702 - accuracy: 0.8353 - val_loss: 0.4586 - val_accuracy: 0.8475\n",
      "Epoch 37/65\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.4651 - accuracy: 0.8412 - val_loss: 0.5400 - val_accuracy: 0.7540\n",
      "Epoch 38/65\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.4610 - accuracy: 0.8467 - val_loss: 0.4613 - val_accuracy: 0.8438\n",
      "Epoch 39/65\n",
      "60000/60000 [==============================] - 20s 342us/sample - loss: 0.4599 - accuracy: 0.8467 - val_loss: 0.4508 - val_accuracy: 0.8590\n",
      "Epoch 40/65\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.4563 - accuracy: 0.8512 - val_loss: 0.4555 - val_accuracy: 0.8522\n",
      "Epoch 41/65\n",
      "60000/60000 [==============================] - 21s 353us/sample - loss: 0.4553 - accuracy: 0.8515 - val_loss: 0.4438 - val_accuracy: 0.8653\n",
      "Epoch 42/65\n",
      "60000/60000 [==============================] - 20s 337us/sample - loss: 0.4528 - accuracy: 0.8540 - val_loss: 0.4572 - val_accuracy: 0.8495\n",
      "Epoch 43/65\n",
      "60000/60000 [==============================] - 20s 341us/sample - loss: 0.4517 - accuracy: 0.8564 - val_loss: 0.4612 - val_accuracy: 0.8442\n",
      "Epoch 44/65\n",
      "60000/60000 [==============================] - 19s 322us/sample - loss: 0.4470 - accuracy: 0.8613 - val_loss: 0.4342 - val_accuracy: 0.8773\n",
      "Epoch 45/65\n",
      "60000/60000 [==============================] - 19s 324us/sample - loss: 0.4449 - accuracy: 0.8628 - val_loss: 0.4399 - val_accuracy: 0.8684\n",
      "Epoch 46/65\n",
      "60000/60000 [==============================] - 20s 327us/sample - loss: 0.4424 - accuracy: 0.8655 - val_loss: 0.4302 - val_accuracy: 0.8813\n",
      "Epoch 47/65\n",
      "60000/60000 [==============================] - 19s 321us/sample - loss: 0.4401 - accuracy: 0.8677 - val_loss: 0.4317 - val_accuracy: 0.8785\n",
      "Epoch 48/65\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.4410 - accuracy: 0.8669 - val_loss: 0.4460 - val_accuracy: 0.8600\n",
      "Epoch 49/65\n",
      "60000/60000 [==============================] - 19s 314us/sample - loss: 0.4378 - accuracy: 0.8707 - val_loss: 0.4353 - val_accuracy: 0.8730\n",
      "Epoch 50/65\n",
      "60000/60000 [==============================] - 20s 334us/sample - loss: 0.4351 - accuracy: 0.8737 - val_loss: 0.4361 - val_accuracy: 0.8698\n",
      "Epoch 51/65\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.4372 - accuracy: 0.8707 - val_loss: 0.4275 - val_accuracy: 0.8831\n",
      "Epoch 52/65\n",
      "60000/60000 [==============================] - 23s 378us/sample - loss: 0.4374 - accuracy: 0.8709 - val_loss: 0.4326 - val_accuracy: 0.8753\n",
      "Epoch 53/65\n",
      "60000/60000 [==============================] - 21s 350us/sample - loss: 0.4302 - accuracy: 0.8786 - val_loss: 0.4188 - val_accuracy: 0.8937\n",
      "Epoch 54/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.4305 - accuracy: 0.8781 - val_loss: 0.4338 - val_accuracy: 0.8730\n",
      "Epoch 55/65\n",
      "60000/60000 [==============================] - 20s 333us/sample - loss: 0.4290 - accuracy: 0.8799 - val_loss: 0.4217 - val_accuracy: 0.8876\n",
      "Epoch 56/65\n",
      "60000/60000 [==============================] - 22s 360us/sample - loss: 0.4275 - accuracy: 0.8817 - val_loss: 0.4273 - val_accuracy: 0.8804\n",
      "Epoch 57/65\n",
      "60000/60000 [==============================] - 24s 393us/sample - loss: 0.4259 - accuracy: 0.8834 - val_loss: 0.4275 - val_accuracy: 0.8809\n",
      "Epoch 58/65\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.4231 - accuracy: 0.8856 - val_loss: 0.4284 - val_accuracy: 0.8792\n",
      "Epoch 59/65\n",
      "60000/60000 [==============================] - 21s 354us/sample - loss: 0.4239 - accuracy: 0.8848 - val_loss: 0.4212 - val_accuracy: 0.8892\n",
      "Epoch 60/65\n",
      "60000/60000 [==============================] - 21s 348us/sample - loss: 0.4208 - accuracy: 0.8885 - val_loss: 0.4171 - val_accuracy: 0.8936\n",
      "Epoch 61/65\n",
      "60000/60000 [==============================] - 21s 343us/sample - loss: 0.4196 - accuracy: 0.8891 - val_loss: 0.4127 - val_accuracy: 0.8988\n",
      "Epoch 62/65\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.4210 - accuracy: 0.8878 - val_loss: 0.4174 - val_accuracy: 0.8932\n",
      "Epoch 63/65\n",
      "60000/60000 [==============================] - 24s 395us/sample - loss: 0.4179 - accuracy: 0.8913 - val_loss: 0.4103 - val_accuracy: 0.9017\n",
      "Epoch 64/65\n",
      "60000/60000 [==============================] - 22s 367us/sample - loss: 0.4170 - accuracy: 0.8924 - val_loss: 0.4132 - val_accuracy: 0.8962\n",
      "Epoch 65/65\n",
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.4153 - accuracy: 0.8939 - val_loss: 0.4568 - val_accuracy: 0.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9781a32d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(8),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=65,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.3992 - accuracy: 0.9153 - val_loss: 0.4014 - val_accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 22s 366us/sample - loss: 0.3919 - accuracy: 0.9244 - val_loss: 0.3988 - val_accuracy: 0.9151\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.3906 - accuracy: 0.9259 - val_loss: 0.3977 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 384us/sample - loss: 0.3900 - accuracy: 0.9266 - val_loss: 0.3984 - val_accuracy: 0.9158\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 393us/sample - loss: 0.3896 - accuracy: 0.9275 - val_loss: 0.3978 - val_accuracy: 0.9168\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 22s 363us/sample - loss: 0.3894 - accuracy: 0.9275 - val_loss: 0.3981 - val_accuracy: 0.9159\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s 372us/sample - loss: 0.3892 - accuracy: 0.9277 - val_loss: 0.3968 - val_accuracy: 0.9172\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 403us/sample - loss: 0.3891 - accuracy: 0.9276 - val_loss: 0.3971 - val_accuracy: 0.9170\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 395us/sample - loss: 0.3889 - accuracy: 0.9279 - val_loss: 0.3966 - val_accuracy: 0.9176\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.3887 - accuracy: 0.9280 - val_loss: 0.3967 - val_accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa97814d110>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.3884 - accuracy: 0.9290 - val_loss: 0.3967 - val_accuracy: 0.9174\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 21s 352us/sample - loss: 0.3883 - accuracy: 0.9287 - val_loss: 0.3966 - val_accuracy: 0.9175\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.3883 - accuracy: 0.9287 - val_loss: 0.3965 - val_accuracy: 0.9176\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 375us/sample - loss: 0.3883 - accuracy: 0.9289 - val_loss: 0.3965 - val_accuracy: 0.9175\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 392us/sample - loss: 0.3883 - accuracy: 0.9288 - val_loss: 0.3965 - val_accuracy: 0.9175\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.3883 - accuracy: 0.9286 - val_loss: 0.3965 - val_accuracy: 0.9176\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 21s 346us/sample - loss: 0.3883 - accuracy: 0.9288 - val_loss: 0.3965 - val_accuracy: 0.9176\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.3883 - accuracy: 0.9289 - val_loss: 0.3965 - val_accuracy: 0.9176\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 21s 358us/sample - loss: 0.3882 - accuracy: 0.9288 - val_loss: 0.3965 - val_accuracy: 0.9176\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 363us/sample - loss: 0.3882 - accuracy: 0.9290 - val_loss: 0.3966 - val_accuracy: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa97803b4d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xr_tp, yr_d, epochs=10,\n",
    "         validation_data=(Xe_tp, ye_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the models still perform well, surprisingly they do not overperform the base LSTM(10) Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
