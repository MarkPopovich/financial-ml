{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Densely Connected on D2 Labels\n",
    "\n",
    "In this notebook we will attempt to learn on the decision labels 'D2', which have a 50/50 buy/sell split without hold positions indicated. We hope this will be an easier decision function to learn, rather than the 3 class classification of buy/hold/sell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('./data/prepared/august25screenfixed/numpy_matrices/yD2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2000), (30, 2000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y[:, :2000]\n",
    "y_test = y[:, 2000:]\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1), (60000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape([60000, 1])\n",
    "y_test = y_test.reshape([60000, 1])\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/prepared/august25screenfixed/numpy_matrices/Xr3.npy')\n",
    "X_test = np.load('./data/prepared/august25screenfixed/numpy_matrices/Xe3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 116, 3), (60000, 1, 116, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), array([38654, 21346]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), array([33170, 26830]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample to balance classes for training set ?\n",
    "b = np.where(y_train == 1)[0]\n",
    "s = np.where(y_train == 2)[0]\n",
    "\n",
    "bi = np.random.choice(b, size=21000, replace=False)\n",
    "si = np.random.choice(s, size=21000, replace=False)\n",
    "\n",
    "ind = np.concatenate([bi,si])\n",
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), array([21000, 21000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train[ind], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 116, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[ind]\n",
    "X_train = X_train[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 1, 116, 3), (42000, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 116, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape = (42000, 116, 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 1), (40000, 1, 116, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decrease test size for runtime and memory concerns\n",
    "b = np.where(y_test == 1)[0]\n",
    "s = np.where(y_test == 2)[0]\n",
    "\n",
    "bi = np.random.choice(b, size=20000, replace=False)\n",
    "si = np.random.choice(s, size=20000, replace=False)\n",
    "\n",
    "indt = np.concatenate([bi,si])\n",
    "indt.shape\n",
    "\n",
    "y_test = y_test[indt]\n",
    "X_test = X_test[indt]\n",
    "y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(40000, 116, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)[1]/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([1., 2.]), array([21000, 21000])),\n",
       " (array([1., 2.]), array([20000, 20000])))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True),np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([21000, 21000])),\n",
       " (array([0., 1.]), array([20000, 20000])))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[np.where(y_train == 2)] = 0\n",
    "y_test[np.where(y_test == 2)] = 0\n",
    "\n",
    "np.unique(y_train, return_counts=True),np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 3 columns only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the super simple feed forward network seems to perform just as well as the cnn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 141us/sample - loss: 0.6672 - accuracy: 0.5833 - val_loss: 0.7140 - val_accuracy: 0.4987\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 5s 127us/sample - loss: 0.6502 - accuracy: 0.6057 - val_loss: 0.7428 - val_accuracy: 0.4965\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 5s 127us/sample - loss: 0.6460 - accuracy: 0.6126 - val_loss: 0.7388 - val_accuracy: 0.4966\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.6451 - accuracy: 0.6148 - val_loss: 0.7322 - val_accuracy: 0.4995\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.6413 - accuracy: 0.6185 - val_loss: 0.7478 - val_accuracy: 0.5162\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 5s 127us/sample - loss: 0.6376 - accuracy: 0.6232 - val_loss: 0.7445 - val_accuracy: 0.5079\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.6352 - accuracy: 0.6288 - val_loss: 0.7306 - val_accuracy: 0.5113\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 5s 129us/sample - loss: 0.6338 - accuracy: 0.6287 - val_loss: 0.7404 - val_accuracy: 0.5129\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 6s 139us/sample - loss: 0.6308 - accuracy: 0.6311 - val_loss: 0.7353 - val_accuracy: 0.5191\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 6s 136us/sample - loss: 0.6267 - accuracy: 0.6384 - val_loss: 0.7527 - val_accuracy: 0.5148\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 5s 129us/sample - loss: 0.6250 - accuracy: 0.6391 - val_loss: 0.7545 - val_accuracy: 0.5171\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.6220 - accuracy: 0.6415 - val_loss: 0.7189 - val_accuracy: 0.5278\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 5s 130us/sample - loss: 0.6183 - accuracy: 0.6449 - val_loss: 0.7448 - val_accuracy: 0.5183\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.6160 - accuracy: 0.6445 - val_loss: 0.7441 - val_accuracy: 0.5274\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 5s 130us/sample - loss: 0.6131 - accuracy: 0.6484 - val_loss: 0.7598 - val_accuracy: 0.5154\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 6s 138us/sample - loss: 0.6124 - accuracy: 0.6536 - val_loss: 0.7502 - val_accuracy: 0.5171\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 6s 131us/sample - loss: 0.6079 - accuracy: 0.6570 - val_loss: 0.7807 - val_accuracy: 0.5239\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.6096 - accuracy: 0.6532 - val_loss: 0.7358 - val_accuracy: 0.5234\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 6s 131us/sample - loss: 0.6079 - accuracy: 0.6562 - val_loss: 0.7612 - val_accuracy: 0.5345\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.6039 - accuracy: 0.6625 - val_loss: 0.7771 - val_accuracy: 0.5209\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 6s 140us/sample - loss: 0.6014 - accuracy: 0.6632 - val_loss: 0.7616 - val_accuracy: 0.5243\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 0.5948 - accuracy: 0.6700 - val_loss: 0.8195 - val_accuracy: 0.5221\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 6s 131us/sample - loss: 0.5928 - accuracy: 0.6705 - val_loss: 0.8707 - val_accuracy: 0.5167\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.5913 - accuracy: 0.6741 - val_loss: 1.0339 - val_accuracy: 0.5130\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.5935 - accuracy: 0.6719 - val_loss: 0.8600 - val_accuracy: 0.5228\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 0.5920 - accuracy: 0.6747 - val_loss: 0.9177 - val_accuracy: 0.5167\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 5s 130us/sample - loss: 0.5888 - accuracy: 0.6764 - val_loss: 0.9648 - val_accuracy: 0.5128\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 7s 157us/sample - loss: 0.5891 - accuracy: 0.6755 - val_loss: 0.9149 - val_accuracy: 0.5207\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 9s 206us/sample - loss: 0.5886 - accuracy: 0.6757 - val_loss: 0.9177 - val_accuracy: 0.5194\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 6s 146us/sample - loss: 0.5842 - accuracy: 0.6809 - val_loss: 1.0815 - val_accuracy: 0.5231\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 6s 143us/sample - loss: 0.5802 - accuracy: 0.6860 - val_loss: 1.0626 - val_accuracy: 0.5226\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 0.5857 - accuracy: 0.6770 - val_loss: 1.0157 - val_accuracy: 0.5191\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.5822 - accuracy: 0.6813 - val_loss: 1.0050 - val_accuracy: 0.5220\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.5788 - accuracy: 0.6859 - val_loss: 1.1580 - val_accuracy: 0.5196\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.5779 - accuracy: 0.6870 - val_loss: 1.2521 - val_accuracy: 0.5213\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 5s 121us/sample - loss: 0.5737 - accuracy: 0.6936 - val_loss: 1.1642 - val_accuracy: 0.5243\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.5753 - accuracy: 0.6890 - val_loss: 1.2949 - val_accuracy: 0.5200\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.5754 - accuracy: 0.6904 - val_loss: 1.1420 - val_accuracy: 0.5187\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.5756 - accuracy: 0.6907 - val_loss: 1.2178 - val_accuracy: 0.5218\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.5721 - accuracy: 0.6927 - val_loss: 1.1959 - val_accuracy: 0.5176\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 6s 154us/sample - loss: 0.5736 - accuracy: 0.6897 - val_loss: 1.2095 - val_accuracy: 0.5200\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 6s 137us/sample - loss: 0.5715 - accuracy: 0.6934 - val_loss: 1.2712 - val_accuracy: 0.5216\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 6s 148us/sample - loss: 0.5686 - accuracy: 0.6949 - val_loss: 1.5719 - val_accuracy: 0.5213\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 7s 156us/sample - loss: 0.5702 - accuracy: 0.6922 - val_loss: 1.1436 - val_accuracy: 0.5213\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 6s 145us/sample - loss: 0.5708 - accuracy: 0.6910 - val_loss: 1.3661 - val_accuracy: 0.5203\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 5s 113us/sample - loss: 0.5665 - accuracy: 0.6939\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f717d9a163e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.fit(X_train, y_train, epochs=50,\n\u001b[0;32m---> 13\u001b[0;31m          validation_data=(X_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[1;32m    788\u001b[0m               mode, 'end', step, batch_logs)\n\u001b[0;32m--> 789\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(116, 3)),\n",
    "    keras.layers.Dense(116, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07750326, 0.92002517, 0.00247163], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13971"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.8680556e-01, 1.2953308e-02, 2.4112873e-04], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement data augmentation and dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
