{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will edit attempt 1 to try to solve the sine wave without volume interferring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will model a Sine wave with variable Volume over time, and then attempt to build a small neural network capable of returning beta coefficients for 4 variables: Magnitude, Phase Shift, Period, and Intercept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(100, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 35, 91, 73,  1, 63,  7, 40, 76, 71, 80, 39, 42,  0, 32, 54, 86,\n",
       "       11, 19, 84, 52, 35, 98, 95, 61, 10, 97,  2, 51, 25, 51, 33, 58, 60,\n",
       "       77, 70, 69,  6, 59, 90, 13, 97, 97, 74, 39, 13, 25, 82, 47, 10, 80,\n",
       "       75, 55, 76,  7, 84, 66, 85, 86, 15, 92, 24, 15, 76, 65, 14, 29, 78,\n",
       "       96, 28, 33, 47, 47, 97, 72, 40, 83, 17,  3, 47, 28, 39, 12, 11, 58,\n",
       "       49, 53, 90, 32, 11, 47, 67, 39,  4, 81, 61, 49, 29, 98, 48, 45, 46,\n",
       "       37, 10, 49, 69, 97, 48, 83, 87, 58, 94, 32, 95, 29,  8, 52, 69,  5,\n",
       "       47, 25, 75, 81, 87, 53, 50, 99, 35,  4, 44, 44, 67, 72, 96, 19, 84,\n",
       "        2, 34, 14, 38, 94, 44,  3, 94, 93, 72, 16, 15, 65, 50, 61, 66, 16,\n",
       "        7, 87,  4, 80, 72, 89, 76, 51, 46, 29, 23, 58, 67, 49, 67, 39,  8,\n",
       "       29,  9, 59, 10, 32, 37, 52,  0, 36, 50, 67, 47, 37, 10, 19, 30, 65,\n",
       "       59, 47, 16, 71, 34, 12, 26, 50, 46, 10, 48, 75, 53, 21, 49, 96, 14,\n",
       "        7,  7, 92, 80, 32,  6, 73, 84, 48, 91, 83, 48, 31, 23, 19, 16, 43,\n",
       "       32, 37, 29,  5, 68, 97, 15,  2, 58, 30, 28, 92, 67,  5, 88, 20, 86,\n",
       "       24, 53, 11, 20, 94,  6, 35, 71, 11, 75, 68, 90, 97, 32, 69, 48, 41,\n",
       "       16, 38, 45, 31,  2, 42, 36, 37, 38, 84, 17, 86, 21, 92, 74, 88,  0,\n",
       "       41, 25, 16,  7, 49,  8, 25, 86, 77, 84, 79, 85, 16, 37, 38, 17, 65,\n",
       "       89, 58,  2, 82, 51, 29, 78, 84, 97, 83, 86, 49, 77,  5, 44, 11, 59,\n",
       "       56,  9, 64, 98, 41, 96, 38, 64, 98, 75, 50, 17, 16, 20, 63, 12, 37,\n",
       "       60, 33, 95, 81, 39, 26, 40, 17, 19, 24, 66, 82, 36, 38, 23, 68, 20,\n",
       "       41, 12, 13, 17, 59, 12, 49, 46, 65, 53, 98, 27, 19, 56, 32, 14, 73,\n",
       "        8, 26, 40, 46, 36, 55, 16, 28, 94, 40, 54, 16, 67, 77, 82,  0, 91,\n",
       "       73, 26, 25, 84, 83, 43, 84, 66, 48,  5, 63, 93, 54, 91, 16, 76, 74,\n",
       "       43, 62, 17, 62,  8, 68, 50, 48, 49, 37, 72, 67, 40, 14,  2, 43, 83,\n",
       "       35, 99, 11, 13,  6, 43, 56, 22, 64, 70, 93,  2, 50, 71, 93, 98, 58,\n",
       "       14, 80, 10, 68, 28, 15, 16, 47, 76, 62, 29, 84, 95,  5, 44, 28, 51,\n",
       "        5, 85, 56, 28, 29, 45, 98, 89, 12, 50, 97, 46, 35, 32, 86, 93, 35,\n",
       "       16, 16, 33, 46, 87, 70, 71, 48, 21, 79,  8, 29, 44, 48, 79, 50, 80,\n",
       "       76, 84, 68, 68,  0, 23, 75, 19, 84, 41, 24, 52, 13, 11, 28, 22, 64,\n",
       "        3, 42, 92, 85,  5, 86, 22, 40, 54, 86, 55, 38, 95,  0, 55, 66, 10,\n",
       "        8, 64, 67, 31, 30, 33, 95, 32, 33, 65,  8, 30, 63, 93,  3, 61, 89,\n",
       "       96, 41,  1, 23, 94, 83, 26,  0, 53, 60, 66, 37, 95, 87, 93, 85,  8,\n",
       "       41, 68, 41, 95, 95, 27, 58,  2, 73, 86, 90, 87, 23, 61, 64, 97, 37,\n",
       "       87, 11, 52, 44, 89, 15, 25, 53, 83, 43,  6, 28,  8, 91,  1, 70, 66,\n",
       "       66, 68, 62, 27, 13, 15, 93, 88, 81, 47, 84, 13, 94, 29, 18, 83, 68,\n",
       "        5,  7, 35, 10, 30, 98,  9, 78, 33, 11, 48, 70, 18, 39, 86, 67, 39,\n",
       "       40, 11, 57, 31, 34, 54, 12, 50, 70, 56,  5, 40, 94,  1, 22, 57, 65,\n",
       "       89,  3, 68, 55, 61, 36, 78, 86, 97, 63, 11, 79, 44, 77, 46, 98, 46,\n",
       "       34, 13, 13, 44, 53, 98, 74, 99,  0, 11, 40, 33, 30, 15, 40, 19, 75,\n",
       "        7, 65, 18, 41, 30, 38, 53, 42, 76, 41, 71, 85, 95, 78, 34,  7, 91,\n",
       "       80, 36, 28, 41, 65, 75, 41, 30, 86, 85, 15, 30, 44,  6, 48, 31, 73,\n",
       "        8, 58, 51, 36, 81, 91, 20, 79, 49, 52, 92, 47, 57, 71, 40, 23, 33,\n",
       "        2, 22, 34, 61,  4, 64,  7,  9, 59,  2, 74, 13, 29,  9, 31, 36, 38,\n",
       "       95, 68, 50, 96, 78, 30, 27, 54, 77, 26, 30, 84, 71, 69, 30, 47, 81,\n",
       "       70, 60, 10, 40, 33, 76, 28, 86,  7, 26, 15, 52, 48, 48,  4, 35, 87,\n",
       "       73, 73, 98, 31, 35, 47, 43, 56, 96, 91, 43, 63, 58, 61, 63, 14, 36,\n",
       "       67, 54, 20, 24, 37, 56, 46, 89, 38, 73, 28,  8, 17, 29, 31, 19, 89,\n",
       "       36, 72, 75, 34, 39, 89, 72, 53, 85, 82, 46, 14, 17, 76, 38, 69, 58,\n",
       "       26, 42, 15, 73, 32, 10, 31, 29, 59, 73, 19,  5, 34,  1, 42, 76, 65,\n",
       "       48, 89, 48, 45, 70, 95, 82, 36, 22, 82,  3, 68, 26, 67, 36, 73, 18,\n",
       "       53, 43, 54, 70, 65, 58, 92, 36, 53, 21, 49, 48, 71, 78, 56, 54, 54,\n",
       "       67, 35,  4, 57, 32, 70, 86, 92, 78, 37,  3, 58,  9, 96, 12, 34, 25,\n",
       "        6, 15, 19, 79, 88, 84, 82, 23,  6, 66, 74, 17,  6, 65, 14, 63, 73,\n",
       "       94, 72, 49, 88, 15, 77, 33, 56, 36, 97, 53, 77, 30, 37, 77, 11, 81,\n",
       "       26, 83, 51, 65, 88,  8, 41, 13, 21, 38, 90, 70,  8, 64, 30, 78, 34,\n",
       "       49, 39, 15, 56, 22, 67, 50, 58, 43, 84, 85,  4, 27,  8, 25, 13, 37,\n",
       "        8, 48, 96, 72, 64, 33, 14, 47, 17, 93, 97, 25, 34, 68, 85, 59, 24,\n",
       "       35, 86, 82,  0, 28,  7, 99, 46, 49, 75, 85, 43, 93, 98,  0,  4, 63,\n",
       "       72,  5, 58, 13,  6, 97, 19, 28, 63, 31, 86, 54, 91, 50])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.reshape([100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume = np.random.randint(1000, size =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.118396919563253, 19.845360685369922, 5.38233934119589, 30.25150661713596)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.normal(10)\n",
    "B = np.random.normal(20)\n",
    "C = np.random.normal(5)\n",
    "D = np.random.normal(30)\n",
    "\n",
    "A, B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = A sin( (x - B) / C)  + D\n",
    "\n",
    "y = A* np.sin((x - B) / C) + D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = tf.constant([y.astype('float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efedc23eed0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the modules or layers and then build the model \n",
    "\n",
    "Below is an example of layer modules and a class based model in tensorflow. I want to recreate this kind of code for a differentiable sine wave. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results: tf.Tensor([[1.0743237 1.3780822]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Example code\n",
    "### https://www.tensorflow.org/guide\n",
    "\n",
    "class Dense(tf.Module):\n",
    "  def __init__(self, in_features, out_features, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.w = tf.Variable(\n",
    "      tf.random.normal([in_features, out_features]), name='w')\n",
    "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "  def __call__(self, x):\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "class SequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model!\n",
    "my_model = SequentialModule(name=\"the_model\")\n",
    "\n",
    "# Call it, with random results\n",
    "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 0.12768531, -0.145143  ,  0.4702714 ],\n",
       "        [-0.08505119,  0.06562553,  0.30974448],\n",
       "        [-0.07534283, -1.0001352 ,  0.13888702]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-1.2371582 , -0.31285626],\n",
       "        [ 1.2311695 ,  0.04092318],\n",
       "        [ 0.5845687 ,  0.74985194]], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Addition(tf.Module):\n",
    "    def __init__(self, inputs, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.b_1 = tf.Variable(tf.random.normal([inputs]), name='b1')\n",
    "        #self.b_2 = tf.Variable(tf.zeros([inputs]), name='b2')\n",
    "    def __call__(self, x):\n",
    "        out = x + self.b_1\n",
    "        #out = tf.math.multiply(out, self.b_1)\n",
    "        return out\n",
    "    \n",
    "class Multiply(tf.Module):\n",
    "    def __init__(self, inputs, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.b_2 = tf.Variable(tf.random.normal([inputs]), name='b2')\n",
    "    def __call__(self, x):\n",
    "        out = tf.math.multiply(x, self.b_2)\n",
    "        return out\n",
    "\n",
    "class Sinusoid(tf.Module):\n",
    "    def __init__(self, inputs, name=None):\n",
    "        super().__init__(name=name)\n",
    "        #self.b_3 = tf.Variable(tf.random.normal([inputs]), name='b3')\n",
    "    def __call__(self, x):\n",
    "        sine = tf.math.sin(x)\n",
    "        return sine\n",
    "    \n",
    "class Inject(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        #self.b_4 = tf.Variable(tf.random.normal([inputs]), name='b4')\n",
    "    def __call__(self, x, v):\n",
    "        multiple = tf.math.multiply(v, x)\n",
    "        #multiple = tf.math.multiply(multiple, self.b_4)\n",
    "        return multiple\n",
    "    \n",
    "class Sine_Model(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.add_1 = Addition(inputs=1, name='B')\n",
    "        self.mult_1 = Multiply(inputs=1, name='C')\n",
    "        self.sin_1 = Sinusoid(inputs=1)\n",
    "        #self.inject_v = Inject()\n",
    "        self.mult_2 = Multiply(inputs=1, name='A')\n",
    "        self.add_2 = Addition(inputs=1, name='D')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.add_1(x)\n",
    "        x = self.mult_1(x)\n",
    "        x = self.sin_1(x)\n",
    "        #x = self.inject_v(x, v)\n",
    "        x = self.mult_2(x)\n",
    "        x = self.add_2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_model = Sine_Model(name='sine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sine_Model at 0x7efeac6af250>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sine_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b1:0' shape=(1,) dtype=float32, numpy=array([-1.4222311], dtype=float32)>,\n",
       " <tf.Variable 'b1:0' shape=(1,) dtype=float32, numpy=array([-0.43879074], dtype=float32)>,\n",
       " <tf.Variable 'b2:0' shape=(1,) dtype=float32, numpy=array([-0.65973824], dtype=float32)>,\n",
       " <tf.Variable 'b2:0' shape=(1,) dtype=float32, numpy=array([-0.40075627], dtype=float32)>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sine_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = tf.constant([x.astype('float32')])\n",
    "v2 = tf.constant([Volume.astype('float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.constant([[2.0, 3.0]])\n",
    "v1 = tf.constant([[4.0, 5.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[2., 3.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[4., 5.]], dtype=float32)>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sine_model(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.28970438, -0.09299144]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = A sin( (x - B) / C)  + D\n",
    "var_vals = []\n",
    "for train_var in sine_model.trainable_variables:\n",
    "    var_vals.append(train_var.numpy())\n",
    "    \n",
    "check_output = np.sin(var_vals[2]*(x1 + var_vals[0])) *var_vals[3] + var_vals[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28970438, -0.09299144]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=bool, numpy=array([[ True,  True]])>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output == check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(x):\n",
    "    output = sine_model(x)\n",
    "    \n",
    "    var_vals = []\n",
    "    for train_var in sine_model.trainable_variables:\n",
    "        var_vals.append(train_var.numpy())\n",
    "        \n",
    "    check_output = np.sin(var_vals[2]*(x + var_vals[0])) *var_vals[3] + var_vals[1]\n",
    "    \n",
    "    print(output == check_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True  True  True  True False  True  True  True  True\n",
      "   True  True  True False  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True False  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True False  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True False  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True False  True  True  True\n",
      "   True False  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True False  True  True False  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True False\n",
      "   True  True  True  True  True  True False False  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True False  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True False  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True False  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True False  True  True  True  True  True\n",
      "  False  True  True  True  True  True  True  True False False  True  True\n",
      "   True  True  True  True  True  True  True False  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True False  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  False  True  True  True  True False  True  True  True  True  True False\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True False  True  True  True\n",
      "  False  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True False  True  True  True  True  True  True  True False\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True False  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True False  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True False  True False  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  False  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True False False  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True False  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True False  True  True  True\n",
      "   True  True  True  True  True  True  True  True False  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True False  True  True]], shape=(1, 1000), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "check_output(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_results = sine_model(x2, v2)\n",
    "\n",
    "# var_vals = []\n",
    "# for train_var in sine_model.trainable_variables:\n",
    "#     var_vals.append(train_var.numpy())\n",
    "    \n",
    "# check_results = np.sin(var_vals[3]*(x2 + var_vals[0])) * v2*var_vals[2] + var_vals[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_results == check_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_results, check_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn to solve for variables\n",
    "\n",
    "In the next section, I will test gradient descent to optimize the beta coefficients and solve the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sine_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose a loss object\n",
    "\n",
    "## From the example\n",
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "#train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "#test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "# tf.keras.metrics.MeanSquaredError(\n",
    "#     name='mean_squared_error', dtype=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    #print(loss)\n",
    "    train_loss(loss)\n",
    "    #train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model \n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(x)\n",
    "    t_loss = loss_object(y, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    #test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       " array([[16., 35., 91., 73.,  1., 63.,  7., 40., 76., 71., 80., 39., 42.,\n",
       "          0., 32., 54., 86., 11., 19., 84., 52., 35., 98., 95., 61., 10.,\n",
       "         97.,  2., 51., 25., 51., 33., 58., 60., 77., 70., 69.,  6., 59.,\n",
       "         90., 13., 97., 97., 74., 39., 13., 25., 82., 47., 10., 80., 75.,\n",
       "         55., 76.,  7., 84., 66., 85., 86., 15., 92., 24., 15., 76., 65.,\n",
       "         14., 29., 78., 96., 28., 33., 47., 47., 97., 72., 40., 83., 17.,\n",
       "          3., 47., 28., 39., 12., 11., 58., 49., 53., 90., 32., 11., 47.,\n",
       "         67., 39.,  4., 81., 61., 49., 29., 98., 48., 45., 46., 37., 10.,\n",
       "         49., 69., 97., 48., 83., 87., 58., 94., 32., 95., 29.,  8., 52.,\n",
       "         69.,  5., 47., 25., 75., 81., 87., 53., 50., 99., 35.,  4., 44.,\n",
       "         44., 67., 72., 96., 19., 84.,  2., 34., 14., 38., 94., 44.,  3.,\n",
       "         94., 93., 72., 16., 15., 65., 50., 61., 66., 16.,  7., 87.,  4.,\n",
       "         80., 72., 89., 76., 51., 46., 29., 23., 58., 67., 49., 67., 39.,\n",
       "          8., 29.,  9., 59., 10., 32., 37., 52.,  0., 36., 50., 67., 47.,\n",
       "         37., 10., 19., 30., 65., 59., 47., 16., 71., 34., 12., 26., 50.,\n",
       "         46., 10., 48., 75., 53., 21., 49., 96., 14.,  7.,  7., 92., 80.,\n",
       "         32.,  6., 73., 84., 48., 91., 83., 48., 31., 23., 19., 16., 43.,\n",
       "         32., 37., 29.,  5., 68., 97., 15.,  2., 58., 30., 28., 92., 67.,\n",
       "          5., 88., 20., 86., 24., 53., 11., 20., 94.,  6., 35., 71., 11.,\n",
       "         75., 68., 90., 97., 32., 69., 48., 41., 16., 38., 45., 31.,  2.,\n",
       "         42., 36., 37., 38., 84., 17., 86., 21., 92., 74., 88.,  0., 41.,\n",
       "         25., 16.,  7., 49.,  8., 25., 86., 77., 84., 79., 85., 16., 37.,\n",
       "         38., 17., 65., 89., 58.,  2., 82., 51., 29., 78., 84., 97., 83.,\n",
       "         86., 49., 77.,  5., 44., 11., 59., 56.,  9., 64., 98., 41., 96.,\n",
       "         38., 64., 98., 75., 50., 17., 16., 20., 63., 12., 37., 60., 33.,\n",
       "         95., 81., 39., 26., 40., 17., 19., 24., 66., 82., 36., 38., 23.,\n",
       "         68., 20., 41., 12., 13., 17., 59., 12., 49., 46., 65., 53., 98.,\n",
       "         27., 19., 56., 32., 14., 73.,  8., 26., 40., 46., 36., 55., 16.,\n",
       "         28., 94., 40., 54., 16., 67., 77., 82.,  0., 91., 73., 26., 25.,\n",
       "         84., 83., 43., 84., 66., 48.,  5., 63., 93., 54., 91., 16., 76.,\n",
       "         74., 43., 62., 17., 62.,  8., 68., 50., 48., 49., 37., 72., 67.,\n",
       "         40., 14.,  2., 43., 83., 35., 99., 11., 13.,  6., 43., 56., 22.,\n",
       "         64., 70., 93.,  2., 50., 71., 93., 98., 58., 14., 80., 10., 68.,\n",
       "         28., 15., 16., 47., 76., 62., 29., 84., 95.,  5., 44., 28., 51.,\n",
       "          5., 85., 56., 28., 29., 45., 98., 89., 12., 50., 97., 46., 35.,\n",
       "         32., 86., 93., 35., 16., 16., 33., 46., 87., 70., 71., 48., 21.,\n",
       "         79.,  8., 29., 44., 48., 79., 50., 80., 76., 84., 68., 68.,  0.,\n",
       "         23., 75., 19., 84., 41., 24., 52., 13., 11., 28., 22., 64.,  3.,\n",
       "         42., 92., 85.,  5., 86., 22., 40., 54., 86., 55., 38., 95.,  0.,\n",
       "         55., 66., 10.,  8., 64., 67., 31., 30., 33., 95., 32., 33., 65.,\n",
       "          8., 30., 63., 93.,  3., 61., 89., 96., 41.,  1., 23., 94., 83.,\n",
       "         26.,  0., 53., 60., 66., 37., 95., 87., 93., 85.,  8., 41., 68.,\n",
       "         41., 95., 95., 27., 58.,  2., 73., 86., 90., 87., 23., 61., 64.,\n",
       "         97., 37., 87., 11., 52., 44., 89., 15., 25., 53., 83., 43.,  6.,\n",
       "         28.,  8., 91.,  1., 70., 66., 66., 68., 62., 27., 13., 15., 93.,\n",
       "         88., 81., 47., 84., 13., 94., 29., 18., 83., 68.,  5.,  7., 35.,\n",
       "         10., 30., 98.,  9., 78., 33., 11., 48., 70., 18., 39., 86., 67.,\n",
       "         39., 40., 11., 57., 31., 34., 54., 12., 50., 70., 56.,  5., 40.,\n",
       "         94.,  1., 22., 57., 65., 89.,  3., 68., 55., 61., 36., 78., 86.,\n",
       "         97., 63., 11., 79., 44., 77., 46., 98., 46., 34., 13., 13., 44.,\n",
       "         53., 98., 74., 99.,  0., 11., 40., 33., 30., 15., 40., 19., 75.,\n",
       "          7., 65., 18., 41., 30., 38., 53., 42., 76., 41., 71., 85., 95.,\n",
       "         78., 34.,  7., 91., 80., 36., 28., 41., 65., 75., 41., 30., 86.,\n",
       "         85., 15., 30., 44.,  6., 48., 31., 73.,  8., 58., 51., 36., 81.,\n",
       "         91., 20., 79., 49., 52., 92., 47., 57., 71., 40., 23., 33.,  2.,\n",
       "         22., 34., 61.,  4., 64.,  7.,  9., 59.,  2., 74., 13., 29.,  9.,\n",
       "         31., 36., 38., 95., 68., 50., 96., 78., 30., 27., 54., 77., 26.,\n",
       "         30., 84., 71., 69., 30., 47., 81., 70., 60., 10., 40., 33., 76.,\n",
       "         28., 86.,  7., 26., 15., 52., 48., 48.,  4., 35., 87., 73., 73.,\n",
       "         98., 31., 35., 47., 43., 56., 96., 91., 43., 63., 58., 61., 63.,\n",
       "         14., 36., 67., 54., 20., 24., 37., 56., 46., 89., 38., 73., 28.,\n",
       "          8., 17., 29., 31., 19., 89., 36., 72., 75., 34., 39., 89., 72.,\n",
       "         53., 85., 82., 46., 14., 17., 76., 38., 69., 58., 26., 42., 15.,\n",
       "         73., 32., 10., 31., 29., 59., 73., 19.,  5., 34.,  1., 42., 76.,\n",
       "         65., 48., 89., 48., 45., 70., 95., 82., 36., 22., 82.,  3., 68.,\n",
       "         26., 67., 36., 73., 18., 53., 43., 54., 70., 65., 58., 92., 36.,\n",
       "         53., 21., 49., 48., 71., 78., 56., 54., 54., 67., 35.,  4., 57.,\n",
       "         32., 70., 86., 92., 78., 37.,  3., 58.,  9., 96., 12., 34., 25.,\n",
       "          6., 15., 19., 79., 88., 84., 82., 23.,  6., 66., 74., 17.,  6.,\n",
       "         65., 14., 63., 73., 94., 72., 49., 88., 15., 77., 33., 56., 36.,\n",
       "         97., 53., 77., 30., 37., 77., 11., 81., 26., 83., 51., 65., 88.,\n",
       "          8., 41., 13., 21., 38., 90., 70.,  8., 64., 30., 78., 34., 49.,\n",
       "         39., 15., 56., 22., 67., 50., 58., 43., 84., 85.,  4., 27.,  8.,\n",
       "         25., 13., 37.,  8., 48., 96., 72., 64., 33., 14., 47., 17., 93.,\n",
       "         97., 25., 34., 68., 85., 59., 24., 35., 86., 82.,  0., 28.,  7.,\n",
       "         99., 46., 49., 75., 85., 43., 93., 98.,  0.,  4., 63., 72.,  5.,\n",
       "         58., 13.,  6., 97., 19., 28., 63., 31., 86., 54., 91., 50.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       " array([[283., 746.,  36.,  21.,  62., 975., 518., 840.,  96., 878., 979.,\n",
       "         156., 167., 913., 618., 257., 386.,  67., 550., 270., 271., 270.,\n",
       "         817.,  82., 787.,  58., 251., 960., 567., 954., 471., 664., 405.,\n",
       "         493., 164., 761., 691., 889., 532., 416.,  57., 161., 617., 818.,\n",
       "         174., 987., 206., 403., 230., 371., 475., 915.,   7., 748., 193.,\n",
       "         452., 671., 998., 885.,  48., 172., 392., 831., 280., 803., 975.,\n",
       "         124.,  17., 483., 539., 414., 993., 471., 430., 170., 133., 415.,\n",
       "         138., 811., 974., 323., 595., 416., 757., 729., 508., 414., 867.,\n",
       "         863., 734., 129., 956.,  73., 732., 302., 658., 731., 358., 325.,\n",
       "         463., 736.,   7., 315., 844., 185., 628., 631., 293., 404., 620.,\n",
       "         716., 697., 698., 589., 450., 885., 665., 494., 498., 866., 200.,\n",
       "          51., 698., 253., 528., 599., 555.,   4., 443., 239., 471., 477.,\n",
       "          51., 889., 221., 287., 561.,  50., 590., 759., 635., 106., 840.,\n",
       "         600., 525.,  29., 328., 702., 572., 784., 947., 672., 794., 744.,\n",
       "         188., 755., 452., 636., 543., 423., 237., 420., 922., 536., 607.,\n",
       "         536., 840., 853., 812., 871., 762., 108.,  75., 125., 323., 307.,\n",
       "         164., 637., 339., 200., 406.,  56., 323., 123., 968., 993., 315.,\n",
       "         379., 932., 961., 629., 546., 627., 816., 491.,  72., 999., 368.,\n",
       "         490., 840., 766.,  47., 453., 956., 374., 640., 344., 135., 662.,\n",
       "         270., 778., 387., 214., 853.,  24., 789., 438., 845., 913., 136.,\n",
       "         108., 378., 938., 613.,  57.,  59., 434., 584.,  40., 525., 310.,\n",
       "         869., 879., 694., 371., 384., 195., 898., 532., 686., 345., 246.,\n",
       "         348., 225., 772.,  52., 853.,  25.,  19., 432., 369., 759., 911.,\n",
       "         183.,  50., 205.,  42., 247., 180., 754., 808., 614., 702., 866.,\n",
       "         122., 265., 406., 938., 966., 233., 521., 815., 370., 489., 242.,\n",
       "         453., 734., 592., 999., 125., 315., 194., 956.,  95., 808., 737.,\n",
       "         645., 934., 651., 716., 420., 295., 697.,  63.,  12., 296., 258.,\n",
       "         762., 435., 552., 388.,  74., 135., 466., 585., 770., 840., 970.,\n",
       "         757., 624., 411., 922., 420., 105., 797., 247., 186., 823.,  23.,\n",
       "         368., 313., 357., 554., 738., 386., 859., 307.,  56., 636., 477.,\n",
       "          68., 786.,  10., 903., 164., 534., 927., 379.,  72., 646., 846.,\n",
       "         135., 266.,  98., 585., 187., 512., 759., 846.,  34., 168., 231.,\n",
       "         924., 584., 582., 342., 315., 446., 197., 472., 469., 168., 216.,\n",
       "         428., 335.,  33., 436., 876., 758., 304., 276., 769., 875., 226.,\n",
       "         647., 437., 845., 958., 896., 687.,  97., 772., 965., 542.,  73.,\n",
       "         999., 949., 563.,  33., 264., 824., 289., 656., 894., 530., 920.,\n",
       "         952., 574., 487., 578., 567., 687., 994., 959., 330., 221., 528.,\n",
       "         508., 435.,  62., 262., 915., 644., 906., 677., 684., 921., 604.,\n",
       "         796., 210., 713., 607., 320., 351., 736., 998., 326., 354., 159.,\n",
       "         677., 305., 810., 268., 568., 283., 735., 668.,  89.,  48., 899.,\n",
       "         821., 828., 107., 348., 856.,   5.,  84., 709., 336., 602., 802.,\n",
       "         938., 686., 358., 604.,  95.,  37., 338., 577., 645., 850., 746.,\n",
       "         586., 973., 531., 336., 862., 485., 925., 889., 172., 722., 318.,\n",
       "         716., 304., 365., 758., 891., 951., 806., 475., 888.,  81., 190.,\n",
       "         265., 698., 667., 221., 368., 930., 788., 611., 833., 183., 512.,\n",
       "         131., 828., 169., 681., 953., 262., 969., 880., 810., 203.,  58.,\n",
       "         312., 995., 755., 625., 109., 620., 150., 172., 310., 960., 768.,\n",
       "         834., 380., 375., 279., 418., 639., 367.,  78., 289., 386., 332.,\n",
       "         750., 110., 257., 186., 541., 729., 414., 590., 504., 467., 331.,\n",
       "         142., 479.,  59., 248., 492., 223., 527., 282.,  34., 938., 246.,\n",
       "         108., 291., 523.,  51., 807., 857., 764., 423., 673., 710.,  19.,\n",
       "         169., 611.,  51., 770., 227.,  70., 976., 174., 524., 889., 840.,\n",
       "         657., 371., 257.,  84., 295., 470., 700.,  80., 904., 455., 857.,\n",
       "         667., 593., 397., 846., 173., 356., 662.,  55., 383., 221., 431.,\n",
       "         865.,  54., 328., 546., 860., 338., 679., 621., 543., 744., 386.,\n",
       "         401., 400., 363., 544.,  10., 897., 279., 905., 201.,  40., 725.,\n",
       "         473., 129., 387., 801., 164., 437., 424., 979., 162., 356., 341.,\n",
       "         439., 381., 313., 600., 645., 213.,  78., 303., 292., 296., 625.,\n",
       "         306., 292., 140., 917., 152., 164., 606.,  60.,  47., 166., 667.,\n",
       "         130., 582., 714., 638., 461., 237., 193., 613., 797., 884., 106.,\n",
       "         880., 468., 484., 482., 198., 628., 744., 696., 289., 695., 444.,\n",
       "         666., 691., 840., 722., 178., 988., 202., 386., 492., 770., 483.,\n",
       "         412., 781., 488., 333., 580., 478., 223., 623., 810., 469., 249.,\n",
       "         206., 809., 703., 175., 972.,  96., 678.,  24., 337., 160., 165.,\n",
       "         611., 784., 801., 463., 628., 155., 172., 187., 617., 195., 827.,\n",
       "           4., 826., 987.,  57., 677., 999.,  10., 292., 469., 747., 933.,\n",
       "         284., 795., 340., 109., 216., 125., 446., 500., 984., 801.,  49.,\n",
       "         780., 475.,   6., 296.,  15., 805., 417., 325.,  90., 559.,  68.,\n",
       "          77., 679., 635., 395., 946., 823., 725., 543.,  22., 162., 293.,\n",
       "         307.,  86., 559., 127., 908., 209., 198., 388., 852., 842., 350.,\n",
       "         597., 973., 162., 348., 856., 506., 162., 728., 573., 882., 963.,\n",
       "         243., 677., 515.,  96.,   8., 178., 926., 781., 201., 795., 749.,\n",
       "         411., 801., 767., 956., 343., 361., 917., 365., 750., 686., 680.,\n",
       "         991., 962., 973., 930., 399., 784., 803., 596., 930., 781., 409.,\n",
       "         625., 451., 386., 777., 744., 169., 900., 361., 798.,  23., 328.,\n",
       "         721., 799., 205., 851., 430., 569.,  85., 889., 177.,  35., 870.,\n",
       "         787., 166., 728., 295., 196., 584., 627.,  26., 616., 722., 874.,\n",
       "         147., 503., 947., 974., 319., 958., 827., 366., 671., 816., 125.,\n",
       "         426., 285., 974., 785., 918., 366., 981., 624., 153., 785.,  69.,\n",
       "         438., 520., 995., 315.,  85., 423., 862., 357.,  51., 312., 793.,\n",
       "         524., 388., 582., 300.,  20.,  76., 589., 427., 308., 252., 774.,\n",
       "         309., 291., 378.,  80., 178., 364., 674., 915., 152., 350., 734.,\n",
       "         461., 526., 501., 617., 943., 602., 680., 857., 101., 991., 627.,\n",
       "          49.,  35., 460.,  79., 756., 675., 223., 454., 744., 965., 790.,\n",
       "         545., 772., 695., 129., 636., 214., 740., 377., 947., 312., 353.,\n",
       "         683., 714., 662., 217., 956., 387., 650., 601., 449., 265., 306.,\n",
       "         189.,  50., 158., 487., 860., 773., 311., 901., 994., 214., 507.,\n",
       "         536., 216., 346., 108.,  52., 166., 555.,  62., 249., 222., 385.,\n",
       "         869., 899., 413., 452., 564., 622., 623., 143., 194., 875., 459.,\n",
       "         182., 129., 158., 396., 493., 797., 302., 763., 384., 303., 234.,\n",
       "         718., 322., 126., 767., 754., 896.,  94.,  90., 928.,  84.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       " array([[23.621986, 33.491695, 36.404385, 25.841496, 33.813496, 40.234398,\n",
       "         23.31736 , 24.513247, 21.691813, 29.449083, 20.297903, 26.151493,\n",
       "         21.878874, 35.501675, 38.07169 , 30.883509, 27.500832, 20.15977 ,\n",
       "         28.668818, 24.152996, 27.173628, 33.491695, 39.635273, 40.217163,\n",
       "         40.152344, 20.469042, 40.172985, 32.002712, 25.446043, 38.52701 ,\n",
       "         25.446043, 36.75102 , 37.549873, 39.596436, 20.8424  , 31.326136,\n",
       "         33.1662  , 24.797907, 38.718876, 34.81465 , 20.58198 , 40.172985,\n",
       "         40.172985, 24.235132, 26.151493, 20.58198 , 38.52701 , 21.637573,\n",
       "         20.688122, 20.469042, 20.297903, 22.83585 , 32.73811 , 21.691813,\n",
       "         23.31736 , 24.152996, 37.850437, 25.749434, 27.500832, 22.324028,\n",
       "         37.78234 , 37.309086, 22.324028, 21.691813, 38.953846, 21.298931,\n",
       "         40.28443 , 20.316845, 40.369198, 40.3542  , 36.75102 , 20.688122,\n",
       "         20.688122, 40.172985, 27.599651, 24.513247, 22.766468, 25.14813 ,\n",
       "         30.13165 , 20.688122, 40.3542  , 26.151493, 20.197853, 20.15977 ,\n",
       "         37.549873, 22.540852, 29.007153, 34.81465 , 38.07169 , 20.15977 ,\n",
       "         20.688122, 36.485474, 26.151493, 28.264715, 20.805166, 40.152344,\n",
       "         22.540852, 40.28443 , 39.635273, 21.463242, 20.14074 , 20.24217 ,\n",
       "         29.790104, 20.469042, 22.540852, 33.1662  , 40.172985, 21.463242,\n",
       "         22.766468, 29.346909, 37.549873, 39.72211 , 38.07169 , 40.217163,\n",
       "         40.28443 , 22.075483, 27.173628, 33.1662  , 26.466166, 20.688122,\n",
       "         38.52701 , 22.83585 , 20.805166, 29.346909, 29.007153, 23.88386 ,\n",
       "         38.77458 , 33.491695, 28.264715, 20.38732 , 20.38732 , 36.485474,\n",
       "         27.599651, 40.369198, 28.668818, 24.152996, 32.002712, 35.206635,\n",
       "         21.298931, 27.93086 , 39.72211 , 20.38732 , 30.13165 , 39.72211 ,\n",
       "         38.901085, 27.599651, 23.621986, 22.324028, 38.953846, 23.88386 ,\n",
       "         40.152344, 37.850437, 23.621986, 23.31736 , 29.346909, 28.264715,\n",
       "         20.297903, 27.599651, 33.067856, 21.691813, 25.446043, 20.24217 ,\n",
       "         40.28443 , 35.848232, 37.549873, 36.485474, 22.540852, 36.485474,\n",
       "         26.151493, 22.075483, 40.28443 , 21.115025, 38.718876, 20.469042,\n",
       "         38.07169 , 29.790104, 27.173628, 35.501675, 31.66523 , 23.88386 ,\n",
       "         36.485474, 20.688122, 29.790104, 20.469042, 28.668818, 39.869335,\n",
       "         38.953846, 38.718876, 20.688122, 23.621986, 29.449083, 35.206635,\n",
       "         20.197853, 39.460102, 23.88386 , 20.24217 , 20.469042, 21.463242,\n",
       "         22.83585 , 29.007153, 32.405533, 22.540852, 40.369198, 21.298931,\n",
       "         23.31736 , 23.31736 , 37.78234 , 20.297903, 38.07169 , 24.797907,\n",
       "         25.841496, 24.152996, 21.463242, 36.404385, 22.766468, 21.463242,\n",
       "         39.12319 , 35.848232, 28.668818, 23.621986, 20.973423, 38.07169 ,\n",
       "         29.790104, 40.28443 , 26.466166, 34.905937, 40.172985, 22.324028,\n",
       "         32.002712, 37.549873, 39.869335, 40.3542  , 37.78234 , 36.485474,\n",
       "         26.466166, 31.224121, 30.542177, 27.500832, 37.309086, 29.007153,\n",
       "         20.15977 , 30.542177, 39.72211 , 24.797907, 33.491695, 29.449083,\n",
       "         20.15977 , 22.83585 , 34.905937, 34.81465 , 40.172985, 38.07169 ,\n",
       "         33.1662  , 21.463242, 23.072512, 23.621986, 27.93086 , 20.14074 ,\n",
       "         39.12319 , 32.002712, 21.878874, 31.66523 , 29.790104, 27.93086 ,\n",
       "         24.152996, 25.14813 , 27.500832, 32.405533, 37.78234 , 24.235132,\n",
       "         31.224121, 35.501675, 23.072512, 38.52701 , 23.621986, 23.31736 ,\n",
       "         22.540852, 22.075483, 38.52701 , 27.500832, 20.8424  , 24.152996,\n",
       "         20.13324 , 25.749434, 23.621986, 29.790104, 27.93086 , 25.14813 ,\n",
       "         38.953846, 33.067856, 37.549873, 32.002712, 21.637573, 25.446043,\n",
       "         40.28443 , 20.316845, 24.152996, 40.172985, 22.766468, 27.500832,\n",
       "         22.540852, 20.8424  , 26.466166, 20.38732 , 20.15977 , 38.718876,\n",
       "         34.507126, 21.115025, 39.757725, 39.635273, 23.072512, 40.369198,\n",
       "         27.93086 , 39.757725, 39.635273, 22.83585 , 23.88386 , 25.14813 ,\n",
       "         23.621986, 30.542177, 40.234398, 20.197853, 29.790104, 39.596436,\n",
       "         36.75102 , 40.217163, 20.805166, 26.151493, 39.460102, 24.513247,\n",
       "         25.14813 , 28.668818, 37.309086, 37.850437, 21.637573, 31.66523 ,\n",
       "         27.93086 , 35.848232, 34.905937, 30.542177, 23.072512, 20.197853,\n",
       "         20.58198 , 25.14813 , 38.718876, 20.197853, 22.540852, 20.24217 ,\n",
       "         38.953846, 29.007153, 39.635273, 40.076233, 28.668818, 34.507126,\n",
       "         38.07169 , 21.298931, 25.841496, 22.075483, 39.460102, 24.513247,\n",
       "         20.24217 , 31.66523 , 32.73811 , 23.621986, 40.3542  , 39.72211 ,\n",
       "         24.513247, 30.883509, 23.621986, 36.485474, 20.8424  , 21.637573,\n",
       "         35.501675, 36.404385, 25.841496, 39.460102, 38.52701 , 24.152996,\n",
       "         22.766468, 20.973423, 24.152996, 37.850437, 21.463242, 26.466166,\n",
       "         40.234398, 38.901085, 30.883509, 36.404385, 23.621986, 21.691813,\n",
       "         24.235132, 20.973423, 40.367466, 25.14813 , 40.367466, 22.075483,\n",
       "         34.905937, 23.88386 , 21.463242, 22.540852, 29.790104, 27.599651,\n",
       "         36.485474, 24.513247, 21.298931, 32.002712, 20.973423, 22.766468,\n",
       "         33.491695, 38.77458 , 20.15977 , 20.58198 , 24.797907, 20.973423,\n",
       "         34.507126, 34.194744, 39.757725, 31.326136, 38.901085, 32.002712,\n",
       "         23.88386 , 29.449083, 38.901085, 39.635273, 37.549873, 21.298931,\n",
       "         20.297903, 20.469042, 34.905937, 40.3542  , 22.324028, 23.621986,\n",
       "         20.688122, 21.691813, 40.367466, 40.28443 , 24.152996, 40.217163,\n",
       "         26.466166, 20.38732 , 40.3542  , 25.446043, 26.466166, 25.749434,\n",
       "         34.507126, 40.3542  , 40.28443 , 20.14074 , 39.635273, 33.067856,\n",
       "         20.197853, 23.88386 , 40.172985, 20.24217 , 33.491695, 38.07169 ,\n",
       "         27.500832, 38.901085, 33.491695, 23.621986, 23.621986, 36.75102 ,\n",
       "         20.24217 , 29.346909, 31.326136, 29.449083, 21.463242, 32.405533,\n",
       "         20.13324 , 22.075483, 40.28443 , 20.38732 , 21.463242, 20.13324 ,\n",
       "         23.88386 , 20.297903, 21.691813, 24.152996, 34.905937, 34.905937,\n",
       "         35.501675, 35.848232, 22.83585 , 28.668818, 24.152996, 23.072512,\n",
       "         37.309086, 27.173628, 20.58198 , 20.15977 , 40.3542  , 34.194744,\n",
       "         39.757725, 30.13165 , 21.878874, 37.78234 , 25.749434, 26.466166,\n",
       "         27.500832, 34.194744, 24.513247, 30.883509, 27.500832, 32.73811 ,\n",
       "         27.93086 , 40.217163, 35.501675, 32.73811 , 37.850437, 20.469042,\n",
       "         22.075483, 39.757725, 36.485474, 39.12319 , 39.869335, 36.75102 ,\n",
       "         40.217163, 38.07169 , 36.75102 , 38.953846, 22.075483, 39.869335,\n",
       "         40.234398, 38.901085, 30.13165 , 40.152344, 33.067856, 40.369198,\n",
       "         23.072512, 33.813496, 35.848232, 39.72211 , 22.766468, 39.460102,\n",
       "         35.501675, 29.007153, 39.596436, 37.850437, 29.790104, 40.217163,\n",
       "         29.346909, 38.901085, 25.749434, 22.075483, 23.072512, 34.905937,\n",
       "         23.072512, 40.217163, 40.217163, 40.076233, 37.549873, 32.002712,\n",
       "         25.841496, 27.500832, 34.81465 , 29.346909, 35.848232, 40.152344,\n",
       "         39.757725, 40.172985, 29.790104, 29.346909, 20.15977 , 27.173628,\n",
       "         20.38732 , 33.067856, 22.324028, 38.52701 , 29.007153, 22.766468,\n",
       "         20.973423, 24.797907, 40.3542  , 22.075483, 36.404385, 33.813496,\n",
       "         31.326136, 37.850437, 37.850437, 34.905937, 40.367466, 40.076233,\n",
       "         20.58198 , 22.324028, 38.901085, 31.224121, 20.805166, 20.688122,\n",
       "         24.152996, 20.58198 , 39.72211 , 40.28443 , 26.849934, 22.766468,\n",
       "         34.905937, 26.466166, 23.31736 , 33.491695, 20.469042, 39.869335,\n",
       "         39.635273, 21.115025, 20.316845, 36.75102 , 20.15977 , 21.463242,\n",
       "         31.326136, 26.849934, 26.151493, 27.500832, 36.485474, 26.151493,\n",
       "         24.513247, 20.15977 , 36.12966 , 39.12319 , 35.206635, 30.883509,\n",
       "         20.197853, 23.88386 , 31.326136, 34.507126, 26.466166, 24.513247,\n",
       "         39.72211 , 33.813496, 34.194744, 36.12966 , 38.953846, 33.067856,\n",
       "         30.13165 , 34.905937, 32.73811 , 40.152344, 31.66523 , 20.316845,\n",
       "         27.500832, 40.172985, 40.234398, 20.15977 , 20.13324 , 20.38732 ,\n",
       "         20.8424  , 20.24217 , 39.635273, 20.24217 , 35.206635, 20.58198 ,\n",
       "         20.58198 , 20.38732 , 29.007153, 39.635273, 24.235132, 38.77458 ,\n",
       "         35.501675, 20.15977 , 24.513247, 36.75102 , 39.869335, 22.324028,\n",
       "         24.513247, 28.668818, 22.83585 , 23.31736 , 38.953846, 26.849934,\n",
       "         23.072512, 39.869335, 27.93086 , 29.007153, 21.878874, 21.691813,\n",
       "         23.072512, 29.449083, 25.749434, 40.217163, 20.316845, 35.206635,\n",
       "         23.31736 , 36.404385, 20.297903, 31.66523 , 40.3542  , 23.072512,\n",
       "         38.953846, 22.83585 , 23.072512, 39.869335, 27.500832, 25.749434,\n",
       "         22.324028, 39.869335, 20.38732 , 24.797907, 21.463242, 39.12319 ,\n",
       "         25.841496, 22.075483, 37.549873, 25.446043, 31.66523 , 20.805166,\n",
       "         36.404385, 30.542177, 20.13324 , 22.540852, 27.173628, 37.78234 ,\n",
       "         20.688122, 36.12966 , 29.449083, 24.513247, 35.848232, 36.75102 ,\n",
       "         32.002712, 34.194744, 35.206635, 40.152344, 28.264715, 39.757725,\n",
       "         23.31736 , 21.115025, 38.718876, 32.002712, 24.235132, 20.58198 ,\n",
       "         40.28443 , 21.115025, 39.12319 , 31.66523 , 27.93086 , 40.217163,\n",
       "         34.905937, 23.88386 , 40.369198, 20.316845, 39.869335, 40.076233,\n",
       "         30.883509, 20.8424  , 39.460102, 39.869335, 24.152996, 29.449083,\n",
       "         33.1662  , 39.869335, 20.688122, 20.805166, 31.326136, 39.596436,\n",
       "         20.469042, 24.513247, 36.75102 , 21.691813, 40.3542  , 27.500832,\n",
       "         23.31736 , 39.460102, 22.324028, 27.173628, 21.463242, 21.463242,\n",
       "         28.264715, 33.491695, 29.346909, 25.841496, 25.841496, 39.635273,\n",
       "         39.12319 , 33.491695, 20.688122, 20.973423, 34.507126, 40.369198,\n",
       "         36.404385, 20.973423, 40.234398, 37.549873, 40.152344, 40.234398,\n",
       "         21.298931, 31.66523 , 36.485474, 30.883509, 30.542177, 37.309086,\n",
       "         29.790104, 34.507126, 20.24217 , 33.067856, 27.93086 , 25.841496,\n",
       "         40.3542  , 22.075483, 25.14813 , 40.28443 , 39.12319 , 28.668818,\n",
       "         33.067856, 31.66523 , 27.599651, 22.83585 , 35.206635, 26.151493,\n",
       "         33.067856, 27.599651, 29.007153, 25.749434, 21.637573, 20.24217 ,\n",
       "         21.298931, 25.14813 , 21.691813, 27.93086 , 33.1662  , 37.549873,\n",
       "         39.460102, 21.878874, 22.324028, 25.841496, 38.07169 , 20.469042,\n",
       "         39.12319 , 40.28443 , 38.718876, 25.841496, 28.668818, 26.466166,\n",
       "         35.206635, 33.813496, 21.878874, 21.691813, 38.953846, 21.463242,\n",
       "         33.067856, 21.463242, 20.14074 , 31.326136, 40.217163, 21.637573,\n",
       "         31.66523 , 34.194744, 21.637573, 30.13165 , 34.905937, 39.460102,\n",
       "         36.485474, 31.66523 , 25.841496, 26.849934, 29.007153, 20.973423,\n",
       "         30.883509, 31.326136, 38.953846, 37.549873, 37.78234 , 31.66523 ,\n",
       "         29.007153, 32.405533, 22.540852, 21.463242, 29.449083, 20.316845,\n",
       "         34.507126, 30.883509, 30.883509, 36.485474, 33.491695, 28.264715,\n",
       "         36.12966 , 38.07169 , 31.326136, 27.500832, 37.78234 , 20.316845,\n",
       "         29.790104, 30.13165 , 37.549873, 21.115025, 40.369198, 20.197853,\n",
       "         35.206635, 38.52701 , 24.797907, 22.324028, 28.668818, 20.13324 ,\n",
       "         31.224121, 24.152996, 21.637573, 35.848232, 24.797907, 37.850437,\n",
       "         24.235132, 25.14813 , 24.797907, 38.953846, 21.298931, 40.234398,\n",
       "         25.841496, 39.72211 , 27.599651, 22.540852, 31.224121, 22.324028,\n",
       "         20.8424  , 36.75102 , 34.507126, 31.66523 , 40.172985, 29.007153,\n",
       "         20.8424  , 39.869335, 29.790104, 20.8424  , 20.15977 , 20.805166,\n",
       "         39.460102, 22.766468, 25.446043, 38.953846, 31.224121, 22.075483,\n",
       "         23.072512, 20.58198 , 32.405533, 27.93086 , 34.81465 , 31.326136,\n",
       "         22.075483, 39.757725, 39.869335, 20.316845, 35.206635, 22.540852,\n",
       "         26.151493, 22.324028, 34.507126, 34.194744, 36.485474, 23.88386 ,\n",
       "         37.549873, 20.973423, 24.152996, 25.749434, 28.264715, 40.076233,\n",
       "         22.075483, 38.52701 , 20.58198 , 29.790104, 22.075483, 21.463242,\n",
       "         40.369198, 27.599651, 39.757725, 36.75102 , 21.298931, 20.688122,\n",
       "         25.14813 , 38.901085, 40.172985, 38.52701 , 35.206635, 34.905937,\n",
       "         25.749434, 38.718876, 37.309086, 33.491695, 27.500832, 21.637573,\n",
       "         35.501675, 40.3542  , 23.31736 , 38.77458 , 20.24217 , 22.540852,\n",
       "         22.83585 , 25.749434, 20.973423, 38.901085, 39.635273, 35.501675,\n",
       "         28.264715, 40.234398, 27.599651, 26.466166, 37.549873, 20.58198 ,\n",
       "         24.797907, 40.172985, 28.668818, 40.3542  , 40.234398, 39.12319 ,\n",
       "         27.500832, 30.883509, 36.404385, 23.88386 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, v2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.053672790527344, Test Loss: 52.679195404052734\n",
      "Epoch 2, Loss: 52.679195404052734, Test Loss: 51.47708511352539\n",
      "Epoch 3, Loss: 51.47708511352539, Test Loss: 52.818206787109375\n",
      "Epoch 4, Loss: 52.818206787109375, Test Loss: 53.0960693359375\n",
      "Epoch 5, Loss: 53.0960693359375, Test Loss: 51.81835174560547\n",
      "Epoch 6, Loss: 51.81835174560547, Test Loss: 51.87383270263672\n",
      "Epoch 7, Loss: 51.87383270263672, Test Loss: 51.41260528564453\n",
      "Epoch 8, Loss: 51.41260528564453, Test Loss: 51.590511322021484\n",
      "Epoch 9, Loss: 51.590511322021484, Test Loss: 51.911476135253906\n",
      "Epoch 10, Loss: 51.911476135253906, Test Loss: 51.999603271484375\n",
      "Epoch 11, Loss: 51.999603271484375, Test Loss: 51.57391357421875\n",
      "Epoch 12, Loss: 51.57391357421875, Test Loss: 51.66203308105469\n",
      "Epoch 13, Loss: 51.66203308105469, Test Loss: 51.73280334472656\n",
      "Epoch 14, Loss: 51.73280334472656, Test Loss: 51.57894515991211\n",
      "Epoch 15, Loss: 51.57894515991211, Test Loss: 51.6221809387207\n",
      "Epoch 16, Loss: 51.6221809387207, Test Loss: 51.63886642456055\n",
      "Epoch 17, Loss: 51.63886642456055, Test Loss: 51.738468170166016\n",
      "Epoch 18, Loss: 51.738468170166016, Test Loss: 51.643123626708984\n",
      "Epoch 19, Loss: 51.643123626708984, Test Loss: 51.66588592529297\n",
      "Epoch 20, Loss: 51.66588592529297, Test Loss: 51.5286865234375\n",
      "Epoch 21, Loss: 51.5286865234375, Test Loss: 51.47980499267578\n",
      "Epoch 22, Loss: 51.47980499267578, Test Loss: 51.61370086669922\n",
      "Epoch 23, Loss: 51.61370086669922, Test Loss: 51.606632232666016\n",
      "Epoch 24, Loss: 51.606632232666016, Test Loss: 51.66899871826172\n",
      "Epoch 25, Loss: 51.66899871826172, Test Loss: 51.90526580810547\n",
      "Epoch 26, Loss: 51.90526580810547, Test Loss: 51.55978012084961\n",
      "Epoch 27, Loss: 51.55978012084961, Test Loss: 51.541263580322266\n",
      "Epoch 28, Loss: 51.541263580322266, Test Loss: 51.50776290893555\n",
      "Epoch 29, Loss: 51.50776290893555, Test Loss: 51.46580123901367\n",
      "Epoch 30, Loss: 51.46580123901367, Test Loss: 51.335636138916016\n",
      "Epoch 31, Loss: 51.335636138916016, Test Loss: 51.544586181640625\n",
      "Epoch 32, Loss: 51.544586181640625, Test Loss: 51.1527099609375\n",
      "Epoch 33, Loss: 51.1527099609375, Test Loss: 52.05205535888672\n",
      "Epoch 34, Loss: 52.05205535888672, Test Loss: 52.30941390991211\n",
      "Epoch 35, Loss: 52.30941390991211, Test Loss: 51.774375915527344\n",
      "Epoch 36, Loss: 51.774375915527344, Test Loss: 51.398582458496094\n",
      "Epoch 37, Loss: 51.398582458496094, Test Loss: 51.43439483642578\n",
      "Epoch 38, Loss: 51.43439483642578, Test Loss: 51.408973693847656\n",
      "Epoch 39, Loss: 51.408973693847656, Test Loss: 51.4007568359375\n",
      "Epoch 40, Loss: 51.4007568359375, Test Loss: 52.1602668762207\n",
      "Epoch 41, Loss: 52.1602668762207, Test Loss: 51.77939987182617\n",
      "Epoch 42, Loss: 51.77939987182617, Test Loss: 52.033592224121094\n",
      "Epoch 43, Loss: 52.033592224121094, Test Loss: 51.35624313354492\n",
      "Epoch 44, Loss: 51.35624313354492, Test Loss: 51.60787582397461\n",
      "Epoch 45, Loss: 51.60787582397461, Test Loss: 51.46342849731445\n",
      "Epoch 46, Loss: 51.46342849731445, Test Loss: 51.431915283203125\n",
      "Epoch 47, Loss: 51.431915283203125, Test Loss: 51.6019287109375\n",
      "Epoch 48, Loss: 51.6019287109375, Test Loss: 51.349544525146484\n",
      "Epoch 49, Loss: 51.349544525146484, Test Loss: 51.42182922363281\n",
      "Epoch 50, Loss: 51.42182922363281, Test Loss: 51.30318832397461\n",
      "Epoch 51, Loss: 51.30318832397461, Test Loss: 51.94417190551758\n",
      "Epoch 52, Loss: 51.94417190551758, Test Loss: 51.718509674072266\n",
      "Epoch 53, Loss: 51.718509674072266, Test Loss: 51.525943756103516\n",
      "Epoch 54, Loss: 51.525943756103516, Test Loss: 51.43560028076172\n",
      "Epoch 55, Loss: 51.43560028076172, Test Loss: 51.47138214111328\n",
      "Epoch 56, Loss: 51.47138214111328, Test Loss: 51.445770263671875\n",
      "Epoch 57, Loss: 51.445770263671875, Test Loss: 51.499908447265625\n",
      "Epoch 58, Loss: 51.499908447265625, Test Loss: 51.57835388183594\n",
      "Epoch 59, Loss: 51.57835388183594, Test Loss: 51.373619079589844\n",
      "Epoch 60, Loss: 51.373619079589844, Test Loss: 51.255836486816406\n",
      "Epoch 61, Loss: 51.255836486816406, Test Loss: 51.59739685058594\n",
      "Epoch 62, Loss: 51.59739685058594, Test Loss: 51.604915618896484\n",
      "Epoch 63, Loss: 51.604915618896484, Test Loss: 51.66443634033203\n",
      "Epoch 64, Loss: 51.66443634033203, Test Loss: 51.48388671875\n",
      "Epoch 65, Loss: 51.48388671875, Test Loss: 51.52113342285156\n",
      "Epoch 66, Loss: 51.52113342285156, Test Loss: 51.53089141845703\n",
      "Epoch 67, Loss: 51.53089141845703, Test Loss: 51.54055404663086\n",
      "Epoch 68, Loss: 51.54055404663086, Test Loss: 51.5026969909668\n",
      "Epoch 69, Loss: 51.5026969909668, Test Loss: 51.6036262512207\n",
      "Epoch 70, Loss: 51.6036262512207, Test Loss: 51.44267272949219\n",
      "Epoch 71, Loss: 51.44267272949219, Test Loss: 51.44365310668945\n",
      "Epoch 72, Loss: 51.44365310668945, Test Loss: 51.47209167480469\n",
      "Epoch 73, Loss: 51.47209167480469, Test Loss: 51.47182083129883\n",
      "Epoch 74, Loss: 51.47182083129883, Test Loss: 51.490970611572266\n",
      "Epoch 75, Loss: 51.490970611572266, Test Loss: 51.526798248291016\n",
      "Epoch 76, Loss: 51.526798248291016, Test Loss: 51.4799690246582\n",
      "Epoch 77, Loss: 51.4799690246582, Test Loss: 51.467742919921875\n",
      "Epoch 78, Loss: 51.467742919921875, Test Loss: 51.48281478881836\n",
      "Epoch 79, Loss: 51.48281478881836, Test Loss: 51.4536247253418\n",
      "Epoch 80, Loss: 51.4536247253418, Test Loss: 51.493858337402344\n",
      "Epoch 81, Loss: 51.493858337402344, Test Loss: 51.52495193481445\n",
      "Epoch 82, Loss: 51.52495193481445, Test Loss: 51.472469329833984\n",
      "Epoch 83, Loss: 51.472469329833984, Test Loss: 51.49460220336914\n",
      "Epoch 84, Loss: 51.49460220336914, Test Loss: 51.49198532104492\n",
      "Epoch 85, Loss: 51.49198532104492, Test Loss: 51.45358657836914\n",
      "Epoch 86, Loss: 51.45358657836914, Test Loss: 51.47321701049805\n",
      "Epoch 87, Loss: 51.47321701049805, Test Loss: 51.4697265625\n",
      "Epoch 88, Loss: 51.4697265625, Test Loss: 51.47435760498047\n",
      "Epoch 89, Loss: 51.47435760498047, Test Loss: 51.469093322753906\n",
      "Epoch 90, Loss: 51.469093322753906, Test Loss: 51.46519470214844\n",
      "Epoch 91, Loss: 51.46519470214844, Test Loss: 51.42637634277344\n",
      "Epoch 92, Loss: 51.42637634277344, Test Loss: 51.375648498535156\n",
      "Epoch 93, Loss: 51.375648498535156, Test Loss: 51.51995086669922\n",
      "Epoch 94, Loss: 51.51995086669922, Test Loss: 51.49322509765625\n",
      "Epoch 95, Loss: 51.49322509765625, Test Loss: 51.46565628051758\n",
      "Epoch 96, Loss: 51.46565628051758, Test Loss: 51.60547637939453\n",
      "Epoch 97, Loss: 51.60547637939453, Test Loss: 51.519264221191406\n",
      "Epoch 98, Loss: 51.519264221191406, Test Loss: 51.5894775390625\n",
      "Epoch 99, Loss: 51.5894775390625, Test Loss: 51.46549987792969\n",
      "Epoch 100, Loss: 51.46549987792969, Test Loss: 51.44294738769531\n",
      "Epoch 101, Loss: 51.44294738769531, Test Loss: 51.4110221862793\n",
      "Epoch 102, Loss: 51.4110221862793, Test Loss: 51.816429138183594\n",
      "Epoch 103, Loss: 51.816429138183594, Test Loss: 51.580265045166016\n",
      "Epoch 104, Loss: 51.580265045166016, Test Loss: 51.54159927368164\n",
      "Epoch 105, Loss: 51.54159927368164, Test Loss: 51.485069274902344\n",
      "Epoch 106, Loss: 51.485069274902344, Test Loss: 51.52570343017578\n",
      "Epoch 107, Loss: 51.52570343017578, Test Loss: 51.45722579956055\n",
      "Epoch 108, Loss: 51.45722579956055, Test Loss: 51.41550827026367\n",
      "Epoch 109, Loss: 51.41550827026367, Test Loss: 51.555118560791016\n",
      "Epoch 110, Loss: 51.555118560791016, Test Loss: 51.63998031616211\n",
      "Epoch 111, Loss: 51.63998031616211, Test Loss: 51.490760803222656\n",
      "Epoch 112, Loss: 51.490760803222656, Test Loss: 51.46912384033203\n",
      "Epoch 113, Loss: 51.46912384033203, Test Loss: 51.4976806640625\n",
      "Epoch 114, Loss: 51.4976806640625, Test Loss: 51.553436279296875\n",
      "Epoch 115, Loss: 51.553436279296875, Test Loss: 51.4351806640625\n",
      "Epoch 116, Loss: 51.4351806640625, Test Loss: 51.564918518066406\n",
      "Epoch 117, Loss: 51.564918518066406, Test Loss: 51.46250915527344\n",
      "Epoch 118, Loss: 51.46250915527344, Test Loss: 51.45680618286133\n",
      "Epoch 119, Loss: 51.45680618286133, Test Loss: 51.464515686035156\n",
      "Epoch 120, Loss: 51.464515686035156, Test Loss: 51.540748596191406\n",
      "Epoch 121, Loss: 51.540748596191406, Test Loss: 51.45329666137695\n",
      "Epoch 122, Loss: 51.45329666137695, Test Loss: 51.50553512573242\n",
      "Epoch 123, Loss: 51.50553512573242, Test Loss: 51.48253631591797\n",
      "Epoch 124, Loss: 51.48253631591797, Test Loss: 51.4624137878418\n",
      "Epoch 125, Loss: 51.4624137878418, Test Loss: 51.47310256958008\n",
      "Epoch 126, Loss: 51.47310256958008, Test Loss: 51.459983825683594\n",
      "Epoch 127, Loss: 51.459983825683594, Test Loss: 51.47559356689453\n",
      "Epoch 128, Loss: 51.47559356689453, Test Loss: 51.51871871948242\n",
      "Epoch 129, Loss: 51.51871871948242, Test Loss: 51.47898864746094\n",
      "Epoch 130, Loss: 51.47898864746094, Test Loss: 51.399375915527344\n",
      "Epoch 131, Loss: 51.399375915527344, Test Loss: 51.898048400878906\n",
      "Epoch 132, Loss: 51.898048400878906, Test Loss: 51.68334197998047\n",
      "Epoch 133, Loss: 51.68334197998047, Test Loss: 51.452396392822266\n",
      "Epoch 134, Loss: 51.452396392822266, Test Loss: 51.47797775268555\n",
      "Epoch 135, Loss: 51.47797775268555, Test Loss: 51.49789047241211\n",
      "Epoch 136, Loss: 51.49789047241211, Test Loss: 51.500404357910156\n",
      "Epoch 137, Loss: 51.500404357910156, Test Loss: 51.74543762207031\n",
      "Epoch 138, Loss: 51.74543762207031, Test Loss: 51.64778137207031\n",
      "Epoch 139, Loss: 51.64778137207031, Test Loss: 51.46745300292969\n",
      "Epoch 140, Loss: 51.46745300292969, Test Loss: 51.46363830566406\n",
      "Epoch 141, Loss: 51.46363830566406, Test Loss: 51.60562515258789\n",
      "Epoch 142, Loss: 51.60562515258789, Test Loss: 51.5377082824707\n",
      "Epoch 143, Loss: 51.5377082824707, Test Loss: 51.47209548950195\n",
      "Epoch 144, Loss: 51.47209548950195, Test Loss: 51.45538330078125\n",
      "Epoch 145, Loss: 51.45538330078125, Test Loss: 51.41704559326172\n",
      "Epoch 146, Loss: 51.41704559326172, Test Loss: 51.43195343017578\n",
      "Epoch 147, Loss: 51.43195343017578, Test Loss: 51.46284484863281\n",
      "Epoch 148, Loss: 51.46284484863281, Test Loss: 51.460670471191406\n",
      "Epoch 149, Loss: 51.460670471191406, Test Loss: 51.4735221862793\n",
      "Epoch 150, Loss: 51.4735221862793, Test Loss: 51.47309875488281\n",
      "Epoch 151, Loss: 51.47309875488281, Test Loss: 51.508052825927734\n",
      "Epoch 152, Loss: 51.508052825927734, Test Loss: 51.45120620727539\n",
      "Epoch 153, Loss: 51.45120620727539, Test Loss: 51.50563049316406\n",
      "Epoch 154, Loss: 51.50563049316406, Test Loss: 51.429317474365234\n",
      "Epoch 155, Loss: 51.429317474365234, Test Loss: 51.49143981933594\n",
      "Epoch 156, Loss: 51.49143981933594, Test Loss: 51.467288970947266\n",
      "Epoch 157, Loss: 51.467288970947266, Test Loss: 51.46908950805664\n",
      "Epoch 158, Loss: 51.46908950805664, Test Loss: 51.4654426574707\n",
      "Epoch 159, Loss: 51.4654426574707, Test Loss: 51.48217010498047\n",
      "Epoch 160, Loss: 51.48217010498047, Test Loss: 51.54216003417969\n",
      "Epoch 161, Loss: 51.54216003417969, Test Loss: 51.46891403198242\n",
      "Epoch 162, Loss: 51.46891403198242, Test Loss: 51.42389678955078\n",
      "Epoch 163, Loss: 51.42389678955078, Test Loss: 51.60300827026367\n",
      "Epoch 164, Loss: 51.60300827026367, Test Loss: 51.47357177734375\n",
      "Epoch 165, Loss: 51.47357177734375, Test Loss: 51.429969787597656\n",
      "Epoch 166, Loss: 51.429969787597656, Test Loss: 51.43062973022461\n",
      "Epoch 167, Loss: 51.43062973022461, Test Loss: 51.37089920043945\n",
      "Epoch 168, Loss: 51.37089920043945, Test Loss: 51.453758239746094\n",
      "Epoch 169, Loss: 51.453758239746094, Test Loss: 51.42282485961914\n",
      "Epoch 170, Loss: 51.42282485961914, Test Loss: 51.3668212890625\n",
      "Epoch 171, Loss: 51.3668212890625, Test Loss: 51.46963119506836\n",
      "Epoch 172, Loss: 51.46963119506836, Test Loss: 51.48514938354492\n",
      "Epoch 173, Loss: 51.48514938354492, Test Loss: 51.66918182373047\n",
      "Epoch 174, Loss: 51.66918182373047, Test Loss: 51.43775177001953\n",
      "Epoch 175, Loss: 51.43775177001953, Test Loss: 51.455570220947266\n",
      "Epoch 176, Loss: 51.455570220947266, Test Loss: 51.53599166870117\n",
      "Epoch 177, Loss: 51.53599166870117, Test Loss: 51.60813903808594\n",
      "Epoch 178, Loss: 51.60813903808594, Test Loss: 51.60239028930664\n",
      "Epoch 179, Loss: 51.60239028930664, Test Loss: 51.457435607910156\n",
      "Epoch 180, Loss: 51.457435607910156, Test Loss: 51.4697265625\n",
      "Epoch 181, Loss: 51.4697265625, Test Loss: 51.476959228515625\n",
      "Epoch 182, Loss: 51.476959228515625, Test Loss: 51.46086883544922\n",
      "Epoch 183, Loss: 51.46086883544922, Test Loss: 51.43079376220703\n",
      "Epoch 184, Loss: 51.43079376220703, Test Loss: 51.49323654174805\n",
      "Epoch 185, Loss: 51.49323654174805, Test Loss: 51.58435821533203\n",
      "Epoch 186, Loss: 51.58435821533203, Test Loss: 51.483638763427734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187, Loss: 51.483638763427734, Test Loss: 51.45287322998047\n",
      "Epoch 188, Loss: 51.45287322998047, Test Loss: 51.467796325683594\n",
      "Epoch 189, Loss: 51.467796325683594, Test Loss: 51.44092559814453\n",
      "Epoch 190, Loss: 51.44092559814453, Test Loss: 51.543033599853516\n",
      "Epoch 191, Loss: 51.543033599853516, Test Loss: 51.37411880493164\n",
      "Epoch 192, Loss: 51.37411880493164, Test Loss: 51.44327163696289\n",
      "Epoch 193, Loss: 51.44327163696289, Test Loss: 51.63702392578125\n",
      "Epoch 194, Loss: 51.63702392578125, Test Loss: 51.595584869384766\n",
      "Epoch 195, Loss: 51.595584869384766, Test Loss: 51.47707748413086\n",
      "Epoch 196, Loss: 51.47707748413086, Test Loss: 51.518829345703125\n",
      "Epoch 197, Loss: 51.518829345703125, Test Loss: 51.4399299621582\n",
      "Epoch 198, Loss: 51.4399299621582, Test Loss: 51.51140594482422\n",
      "Epoch 199, Loss: 51.51140594482422, Test Loss: 51.45478820800781\n",
      "Epoch 200, Loss: 51.45478820800781, Test Loss: 51.50775909423828\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    #train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    #test_accuracy.reset_states()\n",
    "\n",
    "    #for images, labels in train_ds:\n",
    "    # from example code, commented out due to dealing with batches\n",
    "    train_step(x2, y2)\n",
    "\n",
    "    #for test_images, test_labels in test_ds:\n",
    "    test_step(x2, y2)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                            train_loss.result(),\n",
    "                            test_loss.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b1:0' shape=(1,) dtype=float32, numpy=array([-42.215176], dtype=float32)>,\n",
       " <tf.Variable 'b1:0' shape=(1,) dtype=float32, numpy=array([29.817675], dtype=float32)>,\n",
       " <tf.Variable 'b2:0' shape=(1,) dtype=float32, numpy=array([70.80642], dtype=float32)>,\n",
       " <tf.Variable 'b2:0' shape=(1,) dtype=float32, numpy=array([0.27792817], dtype=float32)>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sine_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.118396919563253, 19.845360685369922, 5.38233934119589, 30.25150661713596)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = sine_model(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efeac485c10>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y_predicted.numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efeac7b9750>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
