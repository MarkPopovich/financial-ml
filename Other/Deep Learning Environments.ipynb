{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 22 kB/s s eta 0:00:01  |▎                               | 3.1 MB 6.4 MB/s eta 0:00:50     |█▉                              | 18.7 MB 6.4 MB/s eta 0:00:48     |████████▍                       | 83.7 MB 26.5 MB/s eta 0:00:09     |██████████████▎                 | 143.0 MB 18.7 MB/s eta 0:00:10     |███████████████                 | 150.1 MB 18.7 MB/s eta 0:00:10     |███████████████▎                | 153.1 MB 18.7 MB/s eta 0:00:09     |████████████████▋               | 166.3 MB 18.9 MB/s eta 0:00:09     |█████████████████               | 169.8 MB 18.9 MB/s eta 0:00:08     |█████████████████▏              | 172.1 MB 18.9 MB/s eta 0:00:08     |█████████████████▊              | 177.0 MB 36.2 MB/s eta 0:00:04     |███████████████████▍            | 194.1 MB 36.2 MB/s eta 0:00:04     |███████████████████████▋        | 236.0 MB 18.6 MB/s eta 0:00:05     |███████████████████████████▍    | 274.1 MB 20.3 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.27.2)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 13.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.0.0.post20200311)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.11.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Installing collected packages: gast, astunparse, tensorflow-estimator, tensorboard-plugin-wit, tensorboard, keras-preprocessing, tensorflow\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 keras-preprocessing-1.1.2 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gast\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "Successfully installed gast-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gast --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tf-agents\n",
    "!pip install -q 'gym==0.10.11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "                                    shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "                                    shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if action == 1:\n",
    "            self._episode_ended = True\n",
    "        elif action == 0:\n",
    "            new_card = np.random.randint(1, 11)\n",
    "            self._state += new_card\n",
    "        else:\n",
    "            raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "        if self._episode_ended or self._state >= 21:\n",
    "            reward = self._state - 21 if self._state <= 21 else -21\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "        else:\n",
    "            return ts.transition(np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([0], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([3], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([5], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([14], dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-7., dtype=float32), discount=array(0., dtype=float32), observation=array([14], dtype=int32))\n",
      "Final Reward =  -7.0\n"
     ]
    }
   ],
   "source": [
    "get_new_card_action = np.array(0, dtype=np.int32)\n",
    "end_round_action = np.array(1, dtype=np.int32)\n",
    "\n",
    "environment = CardGameEnv()\n",
    "time_step = environment.reset()\n",
    "print(time_step)\n",
    "cumulative_reward = time_step.reward\n",
    "\n",
    "for _ in range(3):\n",
    "    time_step = environment.step(get_new_card_action)\n",
    "    print(time_step)\n",
    "    cumulative_reward += time_step.reward\n",
    "\n",
    "time_step = environment.step(end_round_action)\n",
    "print(time_step)\n",
    "cumulative_reward += time_step.reward\n",
    "print('Final Reward = ', cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "TimeStep Specs: TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(2147483647, dtype=int32)))\n",
      "Action Specs: BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "env = CardGameEnv()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "print(isinstance(tf_env, tf_environment.TFEnvironment))\n",
    "print(\"TimeStep Specs:\", tf_env.time_step_spec())\n",
    "print(\"Action Specs:\", tf_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockMarketEnv(py_environment.PyEnvironment):\n",
    "    '''\n",
    "    Observation: The observation should be a (90,505) matrix\n",
    "    Action: A (505) vector with probabilties from 0 1, max 10 are encoded as 1, all others are 0\n",
    "    Reward: dot product of the (505,1) top 10 choices with the next (1,505) returns\n",
    "    '''\n",
    "    def __init__(self, X):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "                                    shape=(505,1), dtype=np.float64, minimum=0, maximum=1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "                                    shape=(90,505), dtype=np.float64, minimum=-10, maximum=10 ,name='observation')\n",
    "        self._X = X\n",
    "        self._state = np.array(self._X[:90], dtype=np.float64)\n",
    "        self._i = 0\n",
    "        self._episode_ended = False\n",
    "        \n",
    "#         self._step_type_spec = array_spec.BoundedArraySpec(\n",
    "#                                     shape=(1,), dtype=np.int32, name='step_type')\n",
    "#         self._reward_spec = array_spec.BoundedArraySpec(\n",
    "#                                     shape=(1,), dtype=np.float32, name='reward')\n",
    "#         self._discount_spec = array_spec.BoundedArraySpec(\n",
    "#                                     shape=(1,), dtype=np.float32, name='discount')\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = np.array(self._X[:90], dtype=np.float64) ## input array\n",
    "        self._i = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(self._state)\n",
    "\n",
    "    def _step(self, action):\n",
    "        '''\n",
    "        Given a state array:\n",
    "            - Choose the top ten stocks\n",
    "            - Compute the reward by taking the dot product\n",
    "            - Update the new state by taking the next timestep\n",
    "            - Return the ts.transition(new_state, reward, discount=1)\n",
    "        '''\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "        \n",
    "        action_state = action.copy()\n",
    "        action_state[action_state.argsort()[-10:]] = 1\n",
    "        \n",
    "        mask = np.ones(action_state.shape, bool)\n",
    "        mask[a.argsort()[-10:]] = False\n",
    "        action_state[mask] = 0\n",
    "        \n",
    "        reward_state = np.array(self._X[91+self._i], dtype=np.float64)\n",
    "        reward = np.dot(reward_state, action_state)[0]\n",
    "        \n",
    "        self._i += 1\n",
    "        \n",
    "        if self._i + 91 >= self._X.shape[0]:\n",
    "            self._episode_ended = True\n",
    "        \n",
    "        self._state = np.array(self._X[self._i:90+self._i], dtype=np.float64)\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array(self._state, dtype=np.float64), reward=np.array(reward, dtype=np.float32))\n",
    "        else:\n",
    "            return ts.transition(np.array(self._state, dtype=np.float64), reward=np.array(reward, dtype=np.float32), discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([131, 489, 351, 402, 455, 257,  23, 462, 262, 177])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.uniform(0, 1, 505)\n",
    "a.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a.argsort()[-10:]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.argsort()[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([489, 402, 262, 455, 351, 177, 131, 462,  23, 257])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.ones(a.shape, bool)\n",
    "mask[a.argsort()[-10:]] = False\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.918081739513458"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99278274, 0.98663844, 0.99629835, 0.99223001, 0.99552795,\n",
       "       0.98949967, 0.98997428, 0.99115619, 0.99496631, 0.9890078 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[a.astype('bool')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand = np.random.uniform(-1,1,505*180).reshape(180,505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.140540</td>\n",
       "      <td>-0.329190</td>\n",
       "      <td>-0.047001</td>\n",
       "      <td>-0.649297</td>\n",
       "      <td>-0.633723</td>\n",
       "      <td>-0.838608</td>\n",
       "      <td>-0.111109</td>\n",
       "      <td>0.287581</td>\n",
       "      <td>0.193419</td>\n",
       "      <td>-0.045589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.550927</td>\n",
       "      <td>-0.231102</td>\n",
       "      <td>-0.839100</td>\n",
       "      <td>0.961155</td>\n",
       "      <td>0.646570</td>\n",
       "      <td>0.985204</td>\n",
       "      <td>0.674152</td>\n",
       "      <td>-0.357929</td>\n",
       "      <td>0.743289</td>\n",
       "      <td>-0.471797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.423886</td>\n",
       "      <td>0.695772</td>\n",
       "      <td>-0.165877</td>\n",
       "      <td>0.484184</td>\n",
       "      <td>0.670172</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>-0.240509</td>\n",
       "      <td>-0.035103</td>\n",
       "      <td>-0.795709</td>\n",
       "      <td>0.185046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766458</td>\n",
       "      <td>0.514237</td>\n",
       "      <td>0.406589</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.584977</td>\n",
       "      <td>-0.668325</td>\n",
       "      <td>0.783343</td>\n",
       "      <td>0.435287</td>\n",
       "      <td>-0.384862</td>\n",
       "      <td>-0.760927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085121</td>\n",
       "      <td>0.102740</td>\n",
       "      <td>0.279178</td>\n",
       "      <td>-0.211539</td>\n",
       "      <td>0.310252</td>\n",
       "      <td>0.602915</td>\n",
       "      <td>0.491089</td>\n",
       "      <td>0.117420</td>\n",
       "      <td>0.416565</td>\n",
       "      <td>-0.542193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.616642</td>\n",
       "      <td>-0.756611</td>\n",
       "      <td>0.566252</td>\n",
       "      <td>-0.272756</td>\n",
       "      <td>-0.419373</td>\n",
       "      <td>0.357208</td>\n",
       "      <td>-0.607496</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>-0.545897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.462133</td>\n",
       "      <td>-0.130015</td>\n",
       "      <td>-0.727195</td>\n",
       "      <td>-0.464527</td>\n",
       "      <td>-0.623254</td>\n",
       "      <td>-0.883614</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.896452</td>\n",
       "      <td>0.614098</td>\n",
       "      <td>0.104455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870758</td>\n",
       "      <td>-0.863817</td>\n",
       "      <td>0.274780</td>\n",
       "      <td>0.260244</td>\n",
       "      <td>-0.121842</td>\n",
       "      <td>0.257807</td>\n",
       "      <td>0.139573</td>\n",
       "      <td>0.194738</td>\n",
       "      <td>0.149159</td>\n",
       "      <td>0.266315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558112</td>\n",
       "      <td>-0.058520</td>\n",
       "      <td>0.686742</td>\n",
       "      <td>-0.643676</td>\n",
       "      <td>0.658531</td>\n",
       "      <td>0.869654</td>\n",
       "      <td>-0.751750</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.764127</td>\n",
       "      <td>-0.482681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>-0.990344</td>\n",
       "      <td>0.063195</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>-0.552996</td>\n",
       "      <td>0.524431</td>\n",
       "      <td>-0.628807</td>\n",
       "      <td>0.512478</td>\n",
       "      <td>-0.272679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.842858</td>\n",
       "      <td>0.238492</td>\n",
       "      <td>0.377687</td>\n",
       "      <td>-0.245636</td>\n",
       "      <td>0.449620</td>\n",
       "      <td>0.451549</td>\n",
       "      <td>0.368687</td>\n",
       "      <td>-0.606766</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.694301</td>\n",
       "      <td>-0.411061</td>\n",
       "      <td>-0.264308</td>\n",
       "      <td>-0.254222</td>\n",
       "      <td>-0.765083</td>\n",
       "      <td>0.482651</td>\n",
       "      <td>0.375840</td>\n",
       "      <td>-0.251152</td>\n",
       "      <td>0.616515</td>\n",
       "      <td>0.400360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.326593</td>\n",
       "      <td>-0.890037</td>\n",
       "      <td>0.153252</td>\n",
       "      <td>-0.295029</td>\n",
       "      <td>-0.820342</td>\n",
       "      <td>0.412458</td>\n",
       "      <td>0.612178</td>\n",
       "      <td>-0.113631</td>\n",
       "      <td>-0.471429</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394110</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.054923</td>\n",
       "      <td>0.394835</td>\n",
       "      <td>0.273408</td>\n",
       "      <td>-0.727077</td>\n",
       "      <td>-0.024420</td>\n",
       "      <td>0.890272</td>\n",
       "      <td>0.251708</td>\n",
       "      <td>-0.729621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.319389</td>\n",
       "      <td>0.569504</td>\n",
       "      <td>-0.741532</td>\n",
       "      <td>-0.209200</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>-0.937982</td>\n",
       "      <td>-0.294802</td>\n",
       "      <td>-0.588976</td>\n",
       "      <td>-0.755803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350568</td>\n",
       "      <td>0.078743</td>\n",
       "      <td>0.119772</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>0.188037</td>\n",
       "      <td>-0.990717</td>\n",
       "      <td>-0.876366</td>\n",
       "      <td>0.811248</td>\n",
       "      <td>0.610377</td>\n",
       "      <td>-0.891328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.978380</td>\n",
       "      <td>0.322295</td>\n",
       "      <td>-0.667739</td>\n",
       "      <td>0.436656</td>\n",
       "      <td>-0.056940</td>\n",
       "      <td>-0.654141</td>\n",
       "      <td>0.367164</td>\n",
       "      <td>-0.166018</td>\n",
       "      <td>-0.626665</td>\n",
       "      <td>-0.402560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.958491</td>\n",
       "      <td>-0.261104</td>\n",
       "      <td>-0.635241</td>\n",
       "      <td>0.564070</td>\n",
       "      <td>0.786827</td>\n",
       "      <td>-0.714524</td>\n",
       "      <td>0.319717</td>\n",
       "      <td>-0.950689</td>\n",
       "      <td>-0.713407</td>\n",
       "      <td>-0.967913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.138769</td>\n",
       "      <td>-0.294003</td>\n",
       "      <td>-0.778294</td>\n",
       "      <td>-0.414501</td>\n",
       "      <td>0.453309</td>\n",
       "      <td>0.304598</td>\n",
       "      <td>0.494319</td>\n",
       "      <td>-0.291789</td>\n",
       "      <td>0.777809</td>\n",
       "      <td>0.770454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085885</td>\n",
       "      <td>0.345764</td>\n",
       "      <td>-0.230512</td>\n",
       "      <td>0.973105</td>\n",
       "      <td>-0.464954</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.335745</td>\n",
       "      <td>-0.556144</td>\n",
       "      <td>0.284482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.140540 -0.329190 -0.047001 -0.649297 -0.633723 -0.838608 -0.111109   \n",
       "1   -0.423886  0.695772 -0.165877  0.484184  0.670172  0.602067 -0.240509   \n",
       "2    0.085121  0.102740  0.279178 -0.211539  0.310252  0.602915  0.491089   \n",
       "3   -0.462133 -0.130015 -0.727195 -0.464527 -0.623254 -0.883614 -0.459878   \n",
       "4    0.558112 -0.058520  0.686742 -0.643676  0.658531  0.869654 -0.751750   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "175  0.714755  0.842858  0.238492  0.377687 -0.245636  0.449620  0.451549   \n",
       "176 -0.326593 -0.890037  0.153252 -0.295029 -0.820342  0.412458  0.612178   \n",
       "177 -0.319389  0.569504 -0.741532 -0.209200  0.316878  0.939107 -0.937982   \n",
       "178  0.978380  0.322295 -0.667739  0.436656 -0.056940 -0.654141  0.367164   \n",
       "179  0.138769 -0.294003 -0.778294 -0.414501  0.453309  0.304598  0.494319   \n",
       "\n",
       "          7         8         9    ...       495       496       497  \\\n",
       "0    0.287581  0.193419 -0.045589  ... -0.550927 -0.231102 -0.839100   \n",
       "1   -0.035103 -0.795709  0.185046  ... -0.766458  0.514237  0.406589   \n",
       "2    0.117420  0.416565 -0.542193  ...  0.975062  0.616642 -0.756611   \n",
       "3   -0.896452  0.614098  0.104455  ...  0.870758 -0.863817  0.274780   \n",
       "4   -0.127664 -0.764127 -0.482681  ...  0.705809  0.099999 -0.990344   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "175  0.368687 -0.606766  0.817496  ... -0.694301 -0.411061 -0.264308   \n",
       "176 -0.113631 -0.471429  0.732446  ... -0.394110 -0.034896 -0.054923   \n",
       "177 -0.294802 -0.588976 -0.755803  ... -0.350568  0.078743  0.119772   \n",
       "178 -0.166018 -0.626665 -0.402560  ... -0.958491 -0.261104 -0.635241   \n",
       "179 -0.291789  0.777809  0.770454  ... -0.085885  0.345764 -0.230512   \n",
       "\n",
       "          498       499       500       501       502       503       504  \n",
       "0    0.961155  0.646570  0.985204  0.674152 -0.357929  0.743289 -0.471797  \n",
       "1    0.112033  0.584977 -0.668325  0.783343  0.435287 -0.384862 -0.760927  \n",
       "2    0.566252 -0.272756 -0.419373  0.357208 -0.607496  0.123153 -0.545897  \n",
       "3    0.260244 -0.121842  0.257807  0.139573  0.194738  0.149159  0.266315  \n",
       "4    0.063195  0.090226 -0.552996  0.524431 -0.628807  0.512478 -0.272679  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "175 -0.254222 -0.765083  0.482651  0.375840 -0.251152  0.616515  0.400360  \n",
       "176  0.394835  0.273408 -0.727077 -0.024420  0.890272  0.251708 -0.729621  \n",
       "177 -0.063003  0.188037 -0.990717 -0.876366  0.811248  0.610377 -0.891328  \n",
       "178  0.564070  0.786827 -0.714524  0.319717 -0.950689 -0.713407 -0.967913  \n",
       "179  0.973105 -0.464954  0.880892  0.877024  0.335745 -0.556144  0.284482  \n",
       "\n",
       "[180 rows x 505 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = StockMarketEnv(X_rand)\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
